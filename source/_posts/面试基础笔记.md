---
title: 面试基础笔记
date: 2020-06-22 15:42:04
categories: 面试笔记
tags:
- 面试笔记
- Java
- C++
- 操作系统
- 计算机网络
---

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="面试基础笔记/ox1jqm.png">
    <br>
    <div style="color:orange;
    display: inline-block;
    color: #999;
    padding: 2px;">一抹光</div>
</center>


> 本科面试笔记

<!-- more -->

## 一、Java面试笔记
### Java知识点
#### 1.onCreate和onStart的区别？
- onCreate创建与onDestroy销毁；
- onStart可见与onStop不可见；
- onResume可编辑（即焦点）与onPause；
- onCreate只会被调用一次，onStart可以调用多次

#### 2.looper prepare做了什么事情？
- 默认情况下一个线程是不存在消息循环（message loop）的
- 需要调用Looper.prepare()来给线程创建一个消息循环，调用Looper.loop()来使消息循环起作用

#### 3.Https原理及流程

1.客户端向服务器发起HTTPS请求，连接到服务器的443端口

2.服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人。

3.服务器将自己的公钥发送给客户端。

4.客户端收到服务器端的公钥之后，会对公钥进行检查，验证其合法性，如果发现发现公钥有问题，那么HTTPS传输就无法继续。严格的说，这里应该是验证服务器发送的数字证书的合法性，关于客户端如何验证数字证书的合法性，下文会进行说明。如果公钥合格，那么客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，我们将该密钥称之为client key，即客户端密钥，这样在概念上和服务器端的密钥容易进行区分。然后用服务器的公钥对客户端密钥进行非对称加密，这样客户端密钥就变成密文了，至此，HTTPS中的第一次HTTP请求结束。

5.客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端密钥发送给服务器。

6.服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。

7.然后服务器将加密后的密文发送给客户端。

8.客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成。

---

证书：直观的看，证书包括以下这些内容：
```
  1. 证书序列号

  2. 证书过期时间

  3. 站点组织名

  4. 站点DNS主机名

  5. 站点公钥

  6. 证书颁发者名

  7. 证书签名
```

证书链：证书链的出现，其本质是因为如果证书颁发机构过多的话，不容易识别，防伪和管理，于是形成了少数几家国际权威的证书颁发机构，这些机构非常权威，默认是所有人都可信的，它们成为根证书。但是除了这些机构外，其他的机构也需要被信任，因而，需要这些权威的机构去授信颁发证书，于是就形成了一级证书机构，一级证书机构又可以继续授信下级机构，于是成为树状结构，对于任何一个组织到根证书就是链状结构。

假设你想要成为一个受信任的网站或机构，只需要找你的上级机构去颁发证书给你，颁发时你将自己的公钥，host等信息发送到颁发机构，该机构会将自己的证书附上你的信息，并用自己的私钥签名，做成一张新的证书发给你；而这个上级机构他的证书又是同样的方法由CA颁发的。

  那么，其他人怎么确认你的证书是合法的呢。首先你的证书会在https握手过程中被传递到浏览器，浏览器从你的证书中找到了颁发者，从颁发者的证书（如果你电脑上有的话）又找到了CA的证书（CA证书会在操作系统安装时就安装好，所以每个人电脑上都有根证书），使用CA证书中带的公钥来对颁发者证书做验签，一旦匹配，说明你电脑上的颁发者证书不是伪造的，同理，再用颁发者证书中的公钥去验证你的证书，以此证明你的证书不是伪造的。这样整个链状的验证，从而确保你的证书一定是直接或间接从CA签发的，这样浏览器地址栏会显示一个绿色的盾牌，表示你的网站能通过证书验证

  如果你的电脑上没有颁发者证书（断链）或者你自己本身就是自签名证书（自己做CA，但是要记得，人家电脑上并没有装你的自签名根证书），那么浏览器会报警提示不能验证证书，问你是否还需要继续。
  
  [![8WPGOH.png](https://s1.ax1x.com/2020/03/21/8WPGOH.png)](https://imgchr.com/i/8WPGOH)

---
1. 什么是TCP粘包背景

在socket网络编程中，都是端到端通信，由客户端端口+服务端端口+客户端IP+服务端IP+传输协议组成的五元组可以明确的标识一条连接。在TCP的socket编程中，发送端和接收端都有成对的socket。发送端为了将多个发往接收端的包，更加高效的的发给接收端，于是采用了优化算法（Nagle算法），将多次间隔较小、数据量较小的数据，合并成一个数据量大的数据块，然后进行封包。那么这样一来，接收端就必须使用高效科学的拆包机制来分辨这些数据。

2. 什么是TCP粘包问题？

TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

3. 造成TCP粘包的原因

（1）发送方原因
```
TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

1.只有上一个分组得到确认，才会发送下一个分组收集多个小分组，在一个确认到来时一起发送

2.agle算法造成了发送方可能会出现粘包问题
```
（2）接收方原因
```
TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如
果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。
```

4. 什么时候需要处理粘包现象？

- 如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象

- 如果多个分组毫不相干，甚至是并列关系，那么这个时候就一定要处理粘包现象了

5. 如何处理粘包现象？
（1）发送方

对于发送方造成的粘包问题，可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。

（2）接收方

接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

（3）应用层

应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。

解决办法：循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成，但是如何判断每条数据的长度呢？

格式化数据：每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符。
发送长度：发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置。

6. DP会不会产生粘包问题呢？

TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。

---
慢启动（Slow Start）

是传输控制协议（TCP）使用的一种阻塞控制机制。慢启动也叫做指数增长期。慢启动是指每次TCP接收窗口收到确认时都会增长。增加的大小就是已确认段的数目。这种情况一直保持到要么没有收到一些段，要么窗口大小到达预先定义的阈值。如果发生丢失事件，TCP就认为这是网络阻塞，就会采取措施减轻网络拥挤。一旦发生丢失事件或者到达阈值，TCP就会进入线性增长阶段。这时，每经过一个RTT窗口增长一个段

#### 4.HashMap原理
哈希概念
```
把任意长度的输入（又叫做预映射pre-image）通过散列算法变换成固定长度的输出，该输出就是散列值。
```
哈希存储中的碰撞
```
对不同的关键字可能得到同一哈希值，即key1≠key2，而f(key1)=f(key2)，这种现象称碰撞
```
碰撞解决方法
```
开放定址法：当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。

链地址:HashMap中同样哈希值的位置以一串链表存储起来数据
```

HashMap的存储结构
```
数组、链表、红黑树
```

HashMap原理
```
基于hashing原理，通过put()和get()方法储存和获取对象。put()方法: 它调用键对象的hashCode()方法来计算hashcode值，
系统根据hashcode值决定该元素在bucket位置。如果两个对象key的hashcode返回值相同，那他们的存储位置相同，如果这两个Entry的key通过equals比较返回t
rue，新添加Entry的value将覆盖集合中原有Entry的value，但key不会覆盖；如果这两个Entry的key通过equals比较返回false，新添加的Entry将与集合中原有Entry形成Entry链，而且新添加Entry位于Entry链的头部。put源码如下:
```
HashMap和Hashtable的区别
```
HashMap和Hashtable都实现了Map接口，主要的区别有：线程安全性，同步(synchronization)，以及速度。HashMap几乎可以等价于Hashtable，除了HashMap是非synchronized的，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)
```
HashMap和HashSet的区别
```
HashSet实现了Set接口，它不允许集合中有重复的值，HashMap实现了Map接口，Map接口对键值对进行映射。
HashSet扩展了HashMap,所以底层还是用到map存储，存储实现同map一致，HashMap储存键值，HashSet存储对象。
```

重写equals不重写hashcode会出现什么问题

在存储散列集合时(如Set类)，如果原对象.equals(新对象)，但没有对hashCode重写，即两个对象拥有不同的hashcode，则在集合中将会存储两个值相同的对象，从而导致混淆。因此在重写equals方法时，必须重写hashcode方法。


#### 5.gc的几种算法
引用计数法、标记-清除法、复制算法、标记-清除算法

#### 6.ArrayList 和 LinkedList 区别
ArrayList是基于数组实现的，LinkedList是基于双链表实现的

#### 7.gc root 的对象有哪些？
1 、 虚拟机栈（栈帧中的本地变量表）中引用的对象。

2、 本地方法栈中JNI（即一般说的native方法）引用的对象。

3、 方法区中的静态变量和常量引用的对象。

#### 8.java 为什么采用可达性分析不用引用计数器
1 jdk从1.2开始增加了多种引用方式：软引用、弱引用、虚引用，且在不同引用情况下程序应进行不同的操作。如果我们只采用一个引用计数法来计数无法准确的区分这么多种引用的情况。

2 如果一个对象A持有对象B，而对象B也持有一个对象A，那发生了类似操作系统中死锁的循环持有，这种情况下A与B的counter恒大于1，会使得GC永远无法回收这两个对象。

#### 9.线程间通信的几种实现方式
1.使用 volatile 关键字。
基于 volatile 关键字来实现线程间相互通信是使用共享内存的思想，大致意思就是多个线程同时监听一个变量，当这个变量发生变化的时候 ，线程能够感知并执行相应的业务。这也是最简单的一种实现方式

2.使用Object类的wait() 和 notify() 方法。
众所周知，Object类提供了线程间通信的方法：wait()、notify()、notifyaAl()，它们是多线程通信的基础，而这种实现方式的思想自然是线程间通信。

3.使用JUC工具类 CountDownLatch。
jdk1.5之后在java.util.concurrent包下提供了很多并发编程相关的工具类，简化了我们的并发编程代码的书写，***CountDownLatch***基于AQS框架，相当于也是维护了一个线程间共享变量state

#### 10.synchronized和volatile的区别
1.volatile不需要加锁，比synchronized更轻量级，不会阻塞线程；

2.从内存可见性角度，volatile读相当于加锁，volatile写相当于解锁；

3.synchronized既能够保证可见性，又能保证原子性，而volatile只能保证可见性，无法保证原子性。

#### 11.Java对象的4种引用方式
1.强引用。
我们平日里面的用到的new了一个对象就是强引用，例如 Object obj = new Object();当JVM的内存空间不足时，宁愿抛出OutOfMemoryError使得程序异常终止也不愿意回收具有强引用的存活着的对象！

2.软引用。
当JVM认为内存空间不足时，就回去试图回收软引用指向的对象，也就是说在JVM抛出OutOfMemoryError之前，会去清理软引用对象。软引用可以与引用队列(ReferenceQueue)联合使用。

3.弱引用。在GC的时候，不管内存空间足不足都会回收这个对象，同样也可以配合ReferenceQueue 使用，也同样适用于内存敏感的缓存。ThreadLocal中的key就用到了弱引用。

4.幻象引用。虚引用仅仅只是提供了一种确保对象被finalize以后来做某些事情的机制。比如说这个对象被回收之后发一个系统通知啊啥的。虚引用是必须配合ReferenceQueue 使用的，具体使用方法和上面提到软引用的一样。主要用来跟踪对象被垃圾回收的活动。

#### 12.final、finally、finalize的区别

final用于声明属性，方法和类，分别表示属性不可交变，方法不可覆盖，类不可继承。

finally是异常处理语句结构的一部分，表示总是执行。

finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，供垃圾收集时的其他资源回收，例如关闭文件等。

#### 13.finally什么时候使用
finally可以没有，也可以只有一个。无论有没有发生异常，它总会在这个异常处理结构的最后运行。即使你在try块内用return返回了，在返回前，finally总是要执行，这以便让你有机会能够在异常处理最后做一些清理工作。如关闭数据库连接等等。 

#### 14.UDP如何实现可靠传输
传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。

最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。

1、添加seq/ack机制，确保数据发送到对端

2、添加发送和接收缓冲区，主要是用户超时重传。

3、添加超时重传机制。

详细说明：送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。

#### 15.怎么监控卡顿?
ANR-WatchDog是参考Android WatchDog机制（com.android.server.WatchDog.java）起个单独线程向主线程发送一个变量+1操作，自我休眠自定义ANR的阈值，休眠过后判断变量是否+1完成，如果未完成则告警。

FileObserve
有ANR的流程就可以知道/data/anr文件夹的变化代表着ANR的发生，AMS在dumpStackTrace方法中给了我们一些提示。

#### 16.java单例模式大全
```
public class Writer {

        private Writer(){}
        private static volatile Writer writer;
        public static Writer getInstance(){
            if(wrter == null){
                synchronized(Writer.class){
                    if(wrter == null){
                        writer = new Writer();
                    }
                }
            }
            return writer;
    }
}
```

#### 17.Java内存泄漏
在Java中，内存泄漏就是存在一些被分配的对象，这些对象有下面两个特点，首先，这些对象是可达的，即在有向图中，存在通路可以与其相连；其次，这些对象是无用的，即程序以后不会再使用这些对象。如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。

在C ++ 中，内存泄漏的范围更大一些。有些对象被分配了内存空间，然后却不可达，由于C++中没有GC，这些内存将永远收不回来。在Java中，这些不可达的对象都由GC负责回收，因此程序员不需要考虑这部分的内存泄露。

#### 18.JVM中的内存是怎么划分的？
答：JVM中的内存主要划分为5个区域，即方法区，堆内存，程序计数器，虚拟机栈以及本地方法栈。下边是Java虚拟机运行时数据区示意图

方法区：方法区是一个线程之间共享的区域。常量，静态变量以及JIT编译后的代码都在方法区。主要用于存储已被虚拟机加载的类信息，也可以称为“永久代”，垃圾回收效果一般，通过-XX：MaxPermSize控制上限。

堆内存：堆内存是垃圾回收的主要场所，也是线程之间共享的区域，主要用来存储创建的对象实例，通过-Xmx 和-Xms 可以控制大小。

虚拟机栈（栈内存）：栈内存中主要保存局部变量、基本数据类型变量以及堆内存中某个对象的引用变量。每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表，操作数栈，动态链接，方法出口等信息。栈中的栈帧随着方法的进入和退出有条不紊的执行着出栈和入栈的操作。

程序计数器： 程序计数器是当前线程执行的字节码的位置指示器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，是内存区域中唯一一个在虚拟机规范中没有规定任何OutOfMemoryError情况的区域。

本地方法栈： 主要是为JVM提供使用native 方法的服务。

```
栈就像装数据的桶或箱子
 
 我们先从大家比较熟悉的栈说起吧，它是一种具有后进先出性质的数据结构，也就是说后存放的先取，先存放的后取。这就如同我们要取出放在箱子里面底下的东西（放入的比较早的物体），我
 们首先要移开压在它上面的物体（放入的比较晚的物体）。

堆像一棵倒过来的树

而堆就不同了，堆是一种经过排序的树形数据结构，每个结点都有一个值。通常我们所说的堆的数据结构，是指二叉堆。堆的特点是根结点的值最小（或最大），且根结点的两个子树也是一个堆。
由于堆的这个特性，常用来实现优先队列，堆的存取是随意，这就如同我们在图书馆的书架上取书，虽然书的摆放是有顺序的，但是我们想取任意一本时不必像栈一样，先取出前面所有的书，书架这种机制不同于箱子，我们可以直接取出我们想要的书。
```
#### 19.对象创建过程中的内存分配吗？
1.1new指令

虚拟机遇到一条new指令时，首先去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那么须先执行相应的类加载过程。

1.2分配内存

接下来虚拟机将为新生代对象分配内存。对象所需的内存的大小在类加载完成后便可完全确定。分配方式有“指针碰撞（Bump the Pointer）”和“空闲列表（Free List）”两种方式，具体由所采用的垃圾收集器是否带有压缩整理功能决定。

1.3初始化

内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

1.4对象的初始设置

接下来虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头（Object Header）之中。根据虚拟机当前的运行状态的不同，如对否启用偏向锁等，对象头会有不同的设置方式。

1.5<init>方法

在上面的工作都完成了之后，从虚拟机的角度看，一个新的对象已经产生了，但是从Java程序的角度看，对象创建才刚刚开始—<init>方法还没有执行，所有的字段都还为零。所以，一般来说，执行new指令后悔接着执行init方法，把对象按照程序员的意愿进行初始化（应该是将构造函数中的参数赋值给对象的字段），这样一个真正可用的对象才算完全产生出来。

2.1对象头

HotSpot虚拟机的对象头包含两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码(HashCode)、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。

对象的另一部分类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例（并不是所有的虚拟机实现都必须在对象数据上保留类型指针，也就是说，查找对象的元数据信息并不一定要经过对象本身）。

如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据。

元数据：描述数据的数据。对数据及信息资源的描述信息。在Java中，元数据大多表示为注解。

2.2实例数据

实例数据部分是对象真正存储的有效信息，也是在程序代码中定义的各种类型的字段内容，无论从父类继承下来的，还是在子类中定义的，都需要记录起来。这部分的存储顺序会虚拟机默认的分配策略参数和字段在Java源码中定义的顺序影响（相同宽度的字段总是被分配到一起）。

2.3对齐填充

对齐填充部分并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象的起始地址必须是8字节的整数倍，也就是说，对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或者2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。


#### 20.JVM如何判定一个对象是否应该被回收？
答： 判断一个对象是否应该被回收，主要是看其是否还有引用。判断对象是否存在引用关系的方法包括引用计数法以及root根搜索方法。


引用计数法：
是一种比较古老的回收算法。原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只需要收集计数为0的对象。此算法最致命的是无法处理循环引用的问题。


root根搜索方法：
root搜索方法的基本思路就是通过一系列可以做为root的对象作为起始点，从这些节点开始向下搜索。当一个对象到root节点没有任何引用链接时，则证明此对象是可以被回收的。以下对象会被认为是root对象：

栈内存中引用的对象方法区中静态引用和常量引用指向的对象
被启动类（bootstrap加载器）加载的类和创建的对象
Native方法中JNI引用的对象。

#### 21.JVM垃圾回收算法有哪些？
答：HotSpot 虚拟机采用了root根搜索方法来进行内存回收，常见的回收算法有标记-清除算法，复制算法和标记整理算法。

标记-清除算法（Mark-Sweep）：

标记-清除算法执行分两阶段。第一阶段从引用根节点开始标记所有被引用的对象，第二阶段遍历整个堆，把未标记的对象清除。此算法需要暂停整个应用，并且会产生内存碎片。

复制算法：

复制算法把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。复制算法每次只处理正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不会出现“碎片”问题。当然，此算法的缺点也是很明显的，就是需要两倍内存空间。

标记-整理算法：

标记-整理算法结合了“标记-清除”和“复制”两个算法的优点。也是分两阶段，第一阶段从根节点开始标记所有被引用对象，第二阶段遍历整个堆，清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。

#### 22.JVM中的垃圾收集器CMS收集器

CMS收集器是一种以获取最短回收停顿时间为目标的收集器。CMS收集器是基于标记-清除算法实现的，是一种老年代收集器，通常与ParNew一起使用。

CMS的垃圾收集过程分为4步：

- 初始标记：需要“Stop the World”，初始标记仅仅只是标记一下GC Root能直接关联到的对象，速度很快。
- 并发标记：是主要标记过程，这个标记过程是和用户线程并发执行的。
- 重新标记：需要“Stop the World”，为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录（停顿时间比初始标记长，但比并发标记短得多）。
- 并发清除：和用户线程并发执行的，基于标记结果来清理对象。

#### 23.覆盖（@Override）代码
```
public class OverrideTest {
    public static void main(String[] args) {
        new Son().say();
    }
}
class Parent {
    public void say(){
        System.out.println("我是父类中的say方法");
    }
}
class Son extends Parent {
    @Override
    public void say(){
        System.out.println("我是子类中的say方法，我覆盖了父类的方法");
    }
}
```
#### 24.重载代码

```
public class OverLoadTest {
 
    public void method1(String name, int age){
        System.out.println("");
    }
    // 两个方法的参数顺序不同，可以构成方法的重载
    public void method1(int age, String name){
        System.out.println("");
    }
    //---------------------------------------------
    public void method2(String name){
        System.out.println("");
    }
    // 两个方法的参数类型不同，可以构成方法的重载
    public void method2(int age){
        System.out.println("");
    }
 
    //---------------------------------------------
    public void method3(String name){
        System.out.println("");
    }
    // 两个方法的参数个数不同，可以构成方法的重载
    public void method3(int age, int num){
        System.out.println("");
    }
}
```

#### 25.Java中的值传递和引用传递可以解释下吗？
答：值传递和引用传递的解释可以概括如下。

值传递，意味着传递了对象的一个副本，即使副本被改变，也不会影响源对象。

引用传递，意味着传递的并不是实际的对象，而是对象的引用。因此，外部对引用对象的改变会反映到所有的对象上。

#### 26.哪些对象可以被看做是 GC Roots 呢？

1）虚拟机栈（栈帧中的本地变量表）中引用的对象；

2）方法区中的类静态属性引用的对象，常量引用的对象； 


3）本地方法栈中 JNI(Native 方法）引用的对象

#### 27.说下 java 中的线程创建方式，线程池的工作原理。 

java 中有三种创建线程的方式，或者说四种 
```
1.继承 Thread 类实现多线程 
2.实现 Runnable 接口 
3.实现 Callable 接口 
4.通过线程池 
```
线程池的工作原理：

1）当提交一个新任务到线程池时，线程池判断corePoolSize线程池是否都在执行任务，如果有空闲线程，则创建一个新的工作线程来执行任务，直到当前线程数等于corePoolSize；

2）如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；

3）如果阻塞队列满了，那就创建新的线程执行当前任务，直到线程池中的线程数达到maxPoolSize，这时再有任务来，由饱和策略来处理提交的任务

#### 28.java中存在三种调用机制

1：同步调用：一种阻塞式调用，调用方要等待对方执行完毕才返回，它是一种单向调用

2：回调：一种双向调用模式，也就是说，被调用方在接口被调用时也会调用对方的接口；

3：异步调用：一种类似消息或事件的机制，不过它的调用方向刚好相反，接口的服务在收到某种讯息或发生某种事件时，会主动通知客户方（即调用客户方的接口）

具体说来：就是A类中调用B类中的某个方法C，然后B类中反过来调用A类中的方法D，D这个方法就叫回调方法，

举例：老师平时学生布置任务后不可能一直等待和监督学生完成，老师通常会告诉学生，任务完成后给他打个电话或者发个信息，那么学生给老师返回结果的过程需要老师信息，这就是一个回调的过程。

#### 29.新生代和老年代
新生代
```
java新生代垃圾回收运用的是复制算法。

java新生代分为两部分：Eden区和两个Survivor区，它们的比例是8:1:1，两个Survivor区又分为 fromSurvivor区和to Survivor区，其中新生代每次进行Minor GC（新生代的GC）之前，to Survivor区一定是空的。

每当新创建一个对象而此时Eden区内存不足的时候，就会进行Minor GC，然后Eden区仍然活着的对象会复制到to Survivor区，而from Survivor区中年龄超过阀值的对象会保存到老年代中，没有超过阀值的对象会保存到to Survivor区中，然后to Survivor区和from Survivor区互换位置，保证每次都有一块Survivor区是空闲的。

在Survivor区中的对象每经过一次Minor GC年龄就会加1，默认年龄阀值为15，这个阀值可自行设置，设置方法请自行百度。

当Survivor区中年龄相同的对象加起来超过Survivor区一半内存大小的时候，Survivor区就会提前把大于等于此年龄的对象复制到老年代中。

某些大对象（内存大）创建的时候不经过新生代，而是直接放在老年代中，原因是减少每次复制大对象时浪费是时间，所以尽可能减少大对象的创建。

超大的对象直接不经过新生代就进入老年代
```
老年代
```
在进行Minor GC之前，JVM会先检查老年代最大可用连续空间是否大于新生代历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次Minor GC，否则就进行Full GC（全局GC）。
老年代运用标记-整理算法回收垃圾，将存活的对象向一端移动，清楚边界以外的部分。
```

永久代
```
你可以认为是存放一些类的信息，在上一个章节我们知道我们生成的.class就是存放在这个区域的。一般情况下，我们对于jvm调优都是对新生代和老年代进行调优。一般而言永久代保持默认配置就可以了。
```

#### 30.线程死锁：（重点掌握）
死锁是最常见的一种线程活性故障。死锁的起因是多个线程之间相互等待对方而被永远暂停（处于非Runnable）。死锁的产生必须满足如下四个必要条件：
```
资源互斥：一个资源每次只能被一个线程使用

请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放

不剥夺条件：线程已经获得的资源，在未使用完之前，不能强行剥夺

循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系
```
如何避免死锁的发生？
```
粗锁法：使用一个粒度粗的锁来消除“请求与保持条件”，缺点是会明显降低程序的并发性能并且会导致资源的浪费。

锁排序法：（必须回答出来的点）
指定获取锁的顺序，比如某个线程只有获得A锁和B锁，才能对某资源进行操作，在多线程条件下，如何避免死锁？

通过指定锁的获取顺序，比如规定，只有获得A锁的线程才有资格获取B锁，按顺序获取锁就可以避免死锁。这通常被认为是解决死锁很好的一种方法。

使用显式锁中的ReentrantLock.try(long,TimeUnit)来申请锁
```
#### 31.Java单例写法
单线程环境懒汉式
```
/**
 *懒汉式的单例模式   
 * @author ywq
*/
class Single{ 
    private static Single s = null; 
    private Single(){} 
    public static  Single getInstance(){ 
        if(null==s) 
           s = new Single(); 
        return s; 
    } 
}
```
synchronized内部锁来解决多线程环境下的线程安全问题
```
/**
 * 多线程环境下的懒汉式单例模式(DCL，双检锁实现)
 * @author ywq
*/
class Single{ 
    private static Single s = null; 
    private Single(){} 
 
    public static  Single getInstance(){
        if(null==s){
            synchronized(Single.class){
                if(null==s) 
                    s = new Single(); 
            }
        }
        return s; 
    } 
}
```
Instance instance = new Instance()都发生了啥？

具体步骤如下三步所示：

在堆内存上分配对象的内存空间

在堆内存上初始化对象

设置instance指向刚分配的内存地址

第二步和第三步可能会发生重排序，导致引用型变量指向了一个不为null但是也不完整的对象。所以，在多线程下上述的代码会返回一个不完整的对象。根据前面章节所学的内容，我们需要加入一个volatile关键字来禁止指令重排序。
```
/**
 * 多线程环境下的懒汉式单例模式(DCL，双检锁+volatile实现)
 * 加入了volatile变量来禁止指令重排序  
 * @author ywq
*/
class Single{ 
    private static volatile Single s = null; 
    private Single(){} 
 
    public static  Single getInstance(){
        if(null==s){
            synchronized(Single.class){
                if(null==s) 
                    s = new Single(); 
            }
        }
        return s; 
    } 
```
单例模式的优点：单例模式保证了一个类在一个系统中有且只有一个对象实例，减少了系统内存和性能的开销。

#### 32.Thread类的常用方法

```
String getName()　　返回该线程的名称。

void setName(String name)　　改变线程名称，使之与参数 name 相同。

int getPriority() 　　返回线程的优先级。

void setPriority(int newPriority) 　　更改线程的优先级。

boolean isDaemon() 　　测试该线程是否为守护线程。

void setDaemon(boolean on)　　将该线程标记为守护线程或用户线程。

 

static void sleep(long millis)

void interrupt()　　中断线程。

static void yield()　　暂停当前正在执行的线程对象，并执行其他线程。

void join()　　等待该线程终止。

void run()

void start()  

从Object类继承来的方法　　void notify()         void wait()
```

#### 33. 线程交互：互斥与同步

互斥：同一时间只能有一个线程去对临界区进行操作，通过synchronized（intrinsic lock）实现，只有获得lock的线程才能进入synchronized声明的代码块；

同步：线程之间的通信机制；当某些条件不具备时线程处于等待状态，条件满足，需要发出消息来唤醒所有线程；通过wait（）/notify（）/notifyAll（）实现。

Wait Set：可以理解为线程休息室；

　　共享资源/数据又被称为临界区（Critical Section），当有一个线程想要访问共享资源的时候，首先，他需要获得锁，获得锁后进入我们的临界区进行操作，操作过程中，如果发现某些情况不被满足，将调用锁对象上的wait()方法，此时，该线程释放掉锁资源，然后进入到锁对象上的Wait Set，由于这个线程释放掉了我们的锁资源，使得其他线程可以来竞争多资源，所以其他线程获得锁并进入临界区，同时在锁对象上的wait set中有多条线程在等待条件的满足，当我们的当前运行线程执行完某些操作需要通知等待的线程时，调用notify方法将会唤醒所资源所持有的等待区域中的一条线程，是这条线程有机会去进行竞争CPU资源；或者调用notifyAll方法，这时会使wait set中的所有线程被唤醒，从而使得它们有机会在当前线程离开临界资源释放锁之后去竞争临界资源的锁对象。

#### 34.守护线程

Java线程有两类：

用户线程：运行在前台，执行具体的任务；程序的主线程，连接网络的子线程等都是用户线程；

守护线程：运行在后台，为其他前台线程服务；　

守护线程的特点：一旦所有用户线程都结束运行，守护线程会随JVm一起结束工作；

守护线程的应用：数据库连接池中的监测线程；JVM虚拟机启动后的监测线程，最常见的是垃圾回收线程；
　　守护线程的设置：通过调用Thread类的setDaemon(true)方法来设置当前的线程为守护线程；


注意：setDaemon（true）必须在start（）方法之前调用，否则会抛出IllegalThreadStateException异常；守护线程中产生的新线程也是守护线程；不是所有的任务都可以分配给守护线程来执行，比如读写操作或者计算逻辑；

#### 35.synchronized的使用

```
public class T {
    private static int count = 10;
    public synchronized static void m(){ //这里等同于synchronized(packagename.T.class)
        count--;
        System.out.println(Thread.currentThread().getName()+"count="+count);
    }

    public static void nm(){
        synchronized (T.class){ //是class类的对象
            count--;
        }
    }
}
```
上面代码的运行结果为
```
Thread0count=9
Thread2count=8
Thread1count=7
Thread3count=6
Thread4count=5
```
不加synchronized的运行结果为
```
Thread0count=9
Thread2count=7
Thread1count=8
Thread3count=6
Thread4count=5
```

#### 36.同步方法和非同步方法是否可以同时调用？-->可以

```
public class T {
    public synchronized void m1(){
        System.out.println(Thread.currentThread().getName()+"m1 start...");
        try {
            Thread.sleep(10000);
        }catch(InterruptedException e){
            e.printStackTrace();
        }
        System.out.println(Thread.currentThread().getName()+"m1 end...");

    }
    public void m2(){
        try{
            Thread.sleep(5000);
        }catch(InterruptedException e){
            e.printStackTrace();
        }
        System.out.println(Thread.currentThread().getName()+"m2");
    }

    public static void main(String[] args){
        T t = new T();
        new Thread(t::m1,"t1").start();
        new Thread(t::m2,"t2").start();
    }
}
```
运行结果为
```
t1m1 start...
t2m2
t1m1 end...
```
　原子变量最主要的一个特点是所有的操作都是原子的，synchronized关键字也能做到对变量的原子操作，但是成本相对较高，需要获取锁对象，释放锁对象，如果不能获取到锁，还需要阻塞在阻塞队列上进行等待

#### 37.对业务写方法加锁，对业务读方法不加锁，容易产生脏读

```
public class Account {
    String name;
    double balance;
    public synchronized void set(String name,double balance){
        this.name = name;
        try{
            Thread.sleep(2000);
        }catch(InterruptedException e){
            e.printStackTrace();
        }
        this.balance = balance;
    }

    public double getBalance(String name){
        return this.balance;
    }

    public static void main(String[] args){
        Account a = new Account();
        new Thread(()->a.set("zhangsan",100.0)).start();
        try{
            TimeUnit.SECONDS.sleep(2);
        }catch(InterruptedException e){
            e.printStackTrace();
        }
        System.out.println(a.getBalance("zhangsan"));//0.0

        try{
            TimeUnit.SECONDS.sleep(2);
        }catch(InterruptedException e){
            e.printStackTrace();
        }
        System.out.println(a.getBalance("zhangsan"));//100.0
    }
}
```
#### 38.在继承中，子类重写的同步方法可以调用父类的同步方法

```Q2w345
public class T {
    synchronized void m(){
        System.out.println("m start");
        try{
            TimeUnit.SECONDS.sleep(1);
        }catch(InterruptedException e){
            e.printStackTrace();
        }
        System.out.println("m end");
    }
    public static void main(String[] args){
        new TT().m();
    }

}
class TT extends T{
    synchronized void m(){
        System.out.println("child m start");
        super.m();//可以调用父类的同步方法
        System.out.println("child m end");
    }
}
```

#### 39.出现异常，默认情况下锁会被释放

```
/**
 * 程序在执行过程中如果出现异常，默认情况下锁会被释放
 * 所以在执行并发处理的过程中，有异常要小心，不然可能会发生不一致的情况；
 * 比如，在一个web app处理过程中，多个servlet线程共同访问一个资源
 * 这是如果异常处理不合适，在第一个线程中抛出异常，其他线程就会进入同步代码区，
 * 有可能会访问到异常产生时的数据（处理了一半的数据），
 * 因此要非常小心处理同步业务逻辑中的异常
 */

import java.util.concurrent.TimeUnit;
public class T {
    int count = 0;
    synchronized void m(){
        System.out.println(Thread.currentThread().getName()+"start");
        while(true){
            count++;
            System.out.println(Thread.currentThread().getName()+"count"+count);
            try{
                TimeUnit.SECONDS.sleep(1);
            }catch(InterruptedException e){
                e.printStackTrace();
            }
            if(count==5){
                int i=1/0;//此处抛出异常，锁被释放，要想不被释放，可以在这里进行catch，然后让循环继续

            }
        }
    }
    public static void main(String[] args){
        T t = new T();
        Runnable r = new Runnable(){
            public void run(){
                t.m();
            }
        };
        new Thread(r,"t1").start();
        try{
            TimeUnit.SECONDS.sleep(3);
        }catch(InterruptedException e){
            e.printStackTrace();
        }
        new Thread(r,"t2").start();
    }
}
```
#### 40.volatile的可见性
 volatile 关键字，使一个变量在多个线程间可见，A B 线程都用到一个变量，java默认是A线程中保存一份copy，这样如果B线程修改了该变量，则A未必知道，使用volatile关键字，会让所有线程都会读到变量的修改值；
 
原理
```
第一：使用volatile关键字会强制将修改的值立即写入主存；
第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；
第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。
```

volatile并不能保证多个线程共同修改running变量时所带来的不一致问题，也就是说 volatile不能代替synchronized；

volatile 只保证了原子性，而synchronized既保证可见性有保证原子性，但是synchronized太重了；

#### 41.面试题：实现一个容器，提供两个方法add，size，线程1添加10个元素到容器，线程2监控元素的个数，当个数为5时，线程2提示并结束

```
public class MyContainerVolatile {
    volatile List list = new ArrayList();
    public void add(Object o) {  //add
        list.add(o);
    }
    public int size() {   //size
        return list.size();
    }
 
    public static void main(String[] args) {
        MyContainerVolatile mcv = new MyContainerVolatile();
        new Thread( () -> {  //该线程负责往list里添加
           for (int i=0; i<10; i++) {
               mcv.add(new Object());
               System.out.print(" add-" + i);
               try {
                   Thread.sleep(500);
               } catch (InterruptedException e) {
                   e.printStackTrace();
               }
           }
        },"t1").start();
        new Thread( () -> { //该线程一直监测list的size，直到size=5
            while(true) {  //一直监测着，很浪费CPU
                if(mcv.size() == 5) {  //此处未加同步，仍然可能会出现t1中又一次++为6了，才break
                    break;
                }
            }
            System.out.print(" t2结束 ");
        },"t2").start();
    }
}
```
上面的代码能解决问题，但t2线程的死循环很浪费CPU，影响性能！更优方法是使用wait和notify，请参看下例：

```
public class MyContainerWaitNotify {
    volatile List list = new ArrayList();
    public void add(Object o) {
        list.add(o);
    }
    public int size() {
        return list.size();
    }
 
    public static void main(String[] args) {
        MyContainerWaitNotify mcwn = new MyContainerWaitNotify();
        final Object lock = new Object();
        new Thread(()->{
            synchronized (lock) {
                System.out.print(" ***线程t2启动*** ");
                if (mcwn.size() != 5) {
                    try {
                        lock.wait();  //size不等于5时，就一直在那等着，直到被t1叫醒
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                System.out.print(" ***线程t2结束*** ");
                lock.notify();  //通知t1继续执行
            }
        }, "t2").start();
 
        new Thread(()->{
            synchronized (lock) {
                for(int i=0; i<10; i++) {
                    mcwn.add(new Object());
                    System.out.print(" add-"  + i);
                    if (mcwn.size() == 5) {
                        lock.notify();  //唤醒另一个线程t2，本线程继续执行，直至synchronized包裹的代码块结束或者调用了wait
                        try {
                            lock.wait(); //释放锁，让t2得以执行
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    try {
                        Thread.sleep(1000);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        },"t1").start();
    }
}
```
注意：wait会释放锁，但notify不会，本代码会执行到wait或synchronized块结束才释放锁；

但是，上述的方法还是过于繁琐，Java提供了门闩；

使用CountDownLatch（门闩）的await和countdown方法替代wait和notify方法来进行通知：

```
public class MyContainerLatch {
    volatile List list = new ArrayList(); //添加volatile，使t2能够得到通知
    public void add(Object o) {
        list.add(o);
    }
    public int size() {
        return list.size();
    }
 
    public static void main(String[] args) {
        MyContainerLatch mcl = new MyContainerLatch();
        CountDownLatch latch = new CountDownLatch(1);  //当1变成0时，门就开了
        new Thread(() -> {
            System.out.print(" *t2启动* ");
            if (mcl.size() != 5) {
                try {
                    latch.await();  //等待不需要锁定一个对象
                    //latch.await(5000,TimeUnit.MILLISECONDS); //也可以指定等待时间
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            System.out.print(" *t2结束* ");
        },"t2").start();
        try {
            TimeUnit.SECONDS.sleep(1);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
 
        new Thread(()->{
            System.out.print(" *t1启动* ");
            for (int i=0; i<10; i++) {
                mcl.add(new Object());
                System.out.print(" add-" + i);
                if (mcl.size() == 5) {
                    latch.countDown(); //打开门闩，让t2得以执行。调用一次countDown，就减1
                }
                try {
                    TimeUnit.SECONDS.sleep(1);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            System.out.print(" *t1结束* ");
 
        },"t1").start();
    }
}
```
当不涉及同步，只涉及锁定，用synchronized+wait/notify就显得太重了。这时应该考虑CountDownLatch/cyclicbarrier/semephore


#### 42.ReentrantLock-重入锁

Java中实现锁通常有两种方式，一种是使用synchronized关键字，另一种是Lock：

[synchronized和Lock的区别](https://img2018.cnblogs.com/blog/636698/201905/636698-20190527070802872-536965764.png)

 ReentrantLock替代synchronized

```
public class ReentrantLockTest1 {
    Lock lock = new ReentrantLock();
    void m1() {
        try {
            lock.lock();  //加锁  //相当于synchronized(this)
            for (int i=0; i<10; i++) {
                TimeUnit.SECONDS.sleep(1);
                System.out.print(" " + i);
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            lock.unlock();  //释放锁
        }
    }
    void m2() {
        lock.lock();  //加锁
        System.out.print(" m2()... ");
        lock.unlock();  //释放锁
    }
 
    public static void main(String[] args) {
        ReentrantLockTest1 r1 = new ReentrantLockTest1();
        new Thread(r1::m1).start();
        try {
            TimeUnit.SECONDS.sleep(1);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        new Thread(r1::m2).start();
    }
}
```

#### 43.写一个固定容量的同步容器，有put和get方法，能够支持2个生产者线程以及10个消费者线程的阻塞调用

使用wait和notify/notifyAll来实现：
```
public class MyContainer1<T> {
    final private LinkedList<T> lists = new LinkedList<>();
    final private int MAX =10;
    private int count = 0;

    public synchronized void put(T t){
        while(lists.size()==MAX){
            try{
                this.wait();
            }catch(InterruptedException e){
                e.printStackTrace();
            }
        }
        lists.add(t);
        ++count;
        this.notifyAll();//通知消费者线程进行消费
    }
    public synchronized T get(){
        T t = null;
        //为什么用while? wait 99.9%情况下都是和while一起用的
        //
        while(lists.size()==0){
            try{
                this.wait();
            }catch(InterruptedException e){
                e.printStackTrace();
            }
        }
        t = lists.removeFirst();
        count--;
        this.notifyAll();
        return t;
    }

    public static void main(String[] args){
        MyContainer1<String> c = new MyContainer1<>();
        //启动消费者线程
        for(int i=0; i<10; i++){
            new Thread(()->{
                for(int j=0; j<5; j++){
                    System.out.println(c.get());
                }
            },"c"+i).start();
        }
        try{
            TimeUnit.SECONDS.sleep(2);
        }catch(InterruptedException e){
            e.printStackTrace();
        }

        //启动生产者线程
        for(int i=0;i<2;i++){
            new Thread(()->{
                for(int j =0;j<25;j++){
                    c.put(Thread.currentThread().getName()+" "+j);
                }
            },"p"+i).start();
        }
     }
}
```

使用Lock和Condition的方式可以更加精确地指定哪些线程被唤醒
```
public class MyContainer2<T> {
    final private LinkedList<T> lists= new LinkedList<>();
    final private int MAX =20;
    private int count = 0;

    private Lock lock = new ReentrantLock();
    private Condition producer = lock.newCondition();
    private Condition consumer = lock.newCondition();

    public void put(T t){
        try{
            lock.lock();
            while(lists.size()==MAX){
                producer.await();
            }
            lists.add(t);
            ++count;
            consumer.signalAll();
        }catch(InterruptedException e){
            e.printStackTrace();
        }finally{
            lock.unlock();
        }
    }

    public T get(){
        T t = null;
        try{
            lock.lock();
            while(lists.size()==0){
                consumer.await();
            }
            t=lists.removeFirst();
            count--;
            producer.signalAll();
        }catch(InterruptedException e){
            e.printStackTrace();
        }finally{
            lock.unlock();
        }
        return t;
    }

    public static void main(String[] args){
        MyContainer2<String> c = new MyContainer2();

        for(int i=0; i<10; i++){
            new Thread(()->{
                for(int j=0; j<5; j++){
                    System.out.println(c.get());
                }
            },"c"+i).start();
        }
        try{
            TimeUnit.SECONDS.sleep(2);
        }catch (InterruptedException e){
            e.printStackTrace();
        }

        //启动生产者线程
        for(int i=0;i<2;i++){
            new Thread(()->{
                for(int j =0;j<25;j++){
                    c.put(Thread.currentThread().getName()+" "+j);
                }
            },"p"+i).start();
        }
    }
}
```

#### 44.有N张火车票，每张票都有一个编号，同时有10个窗口对外售票

以下程勋存在重复销售，超量销售问题
```
public class TicketSeller1 {
    static List<String> tickets = new ArrayList<>();
    //初始化，放票
    static{
        for(int i=0; i<10000; i++)
            tickets.add("票编号："+i);
    }

    public static void main(String[] args){
        //启动10个线程不断往外卖票
        for(int i=0;i<10;i++){
            new Thread(()->{
                while(tickets.size()>0){
                    System.out.println("销售了--"+tickets.remove(0));
                }
            }).start();
        }
    }
}
```
改进人存在判断与操作分离了（虽然在vector中size和remove方法都是原子的）问题
```
public class TicketSeller2 {
    //vector本身就是一个同步容器，它所有的方法都是加锁的
    static Vector<String> tickets = new Vector<>();
    static{
        for(int i=0; i<10000; i++)
            tickets.add("票编号："+i);
    }
    public static void main(String[] args){
        for(int i=0; i<10; i++){
            new Thread(()->{
                while(tickets.size()>0){
                    /*
                    try{
                        TimeUnit.SECONDS.sleep(10);
                    }catch(InterruptedException e){
                        e.printStackTrace();
                    }*/
                    System.out.println("销售了--"+tickets.remove(0));
                }
            }).start();
        }
    }
}
```
再改进仍存在加锁效率不高，尤其是每销售一张票都要把整个队列给锁定；

```
public class TicketSeller3 {
    static List<String> tickets = new ArrayList<>();
    static{
        for(int i=0; i<10000; i++)
            tickets.add("票编号："+i);
    }

    public static void main(String[] args){
        //启动10个线程不断往外卖票
        for(int i=0;i<10;i++){
            new Thread(()->{
                while(true){
                    synchronized (tickets){
                        if(tickets.size()<=0) break;
                        try{
                            TimeUnit.SECONDS.sleep(10);
                        }catch(InterruptedException e){
                            e.printStackTrace();
                        }

                        System.out.println("销售了--"+tickets.remove(0));
                    }
                }
            }).start();
        }
    }
}
```
引入并发容器：
```
public class TicketSeller4 {
    //并发容器
    static Queue<String> tickets = new ConcurrentLinkedQueue<>();
    static{
        for(int i=0; i<1000; i++){
            tickets.add("票编号："+i);
        }
    }
    public static void main(String[] args){
        for(int i=0; i<10; i++){
            new Thread(()->{
                while(true){
                    //poll从头往外拿一个数据，是同步的
                    String s = tickets.poll();
                    if(s==null) break;
                    else System.out.println("销售了--"+s);
                }
            }).start();
        }
    }
}
```
if(s==null) break;虽然不是原子性的，但是我们判断以后没有对队列作修改操作，所以这里不会出错。

#### 45.类的加载机制
类的生命周期一共分为5个阶段，加载、连接、初始化、使用、卸载。

[![8wNbWt.md.png](https://s1.ax1x.com/2020/03/18/8wNbWt.md.png)](https://imgchr.com/i/8wNbWt)

加载：类的加载过程主要完成3件事件，1.通过类的全限定名来获取定义此类的二进制字节流，2.将这个类字节流代表的静态存储结构转为方法区的运行时数据结构，3.在堆中生成一个代表此类的java.lang.Class对象，作为访问方法区这些数据结构的入口。这个过程主要是类加载器完成的。

连接：这个过程分3个阶段(校验，准备，解析)完成。首先是校验，此阶段主要校验class文件包含的信息是否符合jvm的规范。具体的校验通过对文件格式，元数据，字节码，符号引用验证来完成。然后是准备，此阶段为类变量分配内存，并将其初始化为默认值。最后是解析，即把类型中的符号引用转换成为直接引用。具体的解析有4种，1.类或接口的解析，2.字段解析，3.类方法解析，4.接口方法解析。完成这3个阶段就完成了类的连接。

初始化：即执行类的构造器方法的过程。有5种方法可以完成初始化：1.调用new方法，2.使用Class类的newInstance方法(反射机制)，3.使用Constructor类的newInstance方法(反射机制)，4.使用Clone方法创建对象，5.使用(反)序列化机制创建对象

使用：完成类的初始化后，就可以对类进行实例化，在程序中进行使用了

卸载：当类被加载，连接和初始化后，它的生命周期就始了，当代表类的class对象不在被引用时，class对象就会结束生命周期，类在方法区内的数据就会被卸载。因此一个类何时结束生命，取决于代表它的class对象何时结束生命。

#### 46.JVM调优

jvm调优没有一个固定模板配置说必须如何操作，它需要根据系统的情况不同对待。

但是可以有如下建议：

1、初始化内存和最大内存尽量保持一致，避免内存不够用继续扩充内存。最大内存不要超过物理内存，例如内存8g，你可以设置最大内存4g/6g但是不能超过8g否则加载类的时候没有空间会报错。

2、gc/full gc频率不要太高、每次gc时间不要太长、根据系统应用来定。

#### 47.对象的内存布局

对象头(Header)：包含两部分，第一部分用于存储对象自身的运行时数据，如哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等，32 位虚拟机占 32 bit，64 位虚拟机占 64 bit。官方称为 ‘Mark Word’。第二部分是类型指针，即对象指向它的类的元数据指针，虚拟机通过这个指针确定这个对象是哪个类的实例。另外，如果是 Java 数组，对象头中还必须有一块用于记录数组长度的数据，因为普通对象可以通过 Java 对象元数据确定大小，而数组对象不可以。

实例数据(Instance Data)：程序代码中所定义的各种类型的字段内容(包含父类继承下来的和子类中定义的)。

对齐填充(Padding)：不是必然需要，主要是占位，保证对象大小是某个字节的整数倍。

#### 48.对象的访问定位

通过句柄访问

Java 堆中会分配一块内存作为句柄池。reference 存储的是句柄地址。详情见图

[![8wYPW6.png](https://s1.ax1x.com/2020/03/18/8wYPW6.png)](https://imgchr.com/i/8wYPW6)

使用直接指针访问

reference 中直接存储对象地址

[![8wYKYt.md.png](https://s1.ax1x.com/2020/03/18/8wYKYt.md.png)](https://imgchr.com/i/8wYKYt)

比较：使用句柄的最大好处是 reference 中存储的是稳定的句柄地址，在对象移动(GC)是只改变实例数据指针地址，reference 自身不需要修改。直接指针访问的最大好处是速度快，节省了一次指针定位的时间开销。如果是对象频繁 GC 那么句柄方法好，如果是对象频繁访问则直接指针访问好。

#### 49.Thread 类中的start() 和 run() 方法有什么区别？
这个问题经常被问到，但还是能从此区分出面试者对Java线程模型的理解程度。start()方法被用来启动新创建的线程，而且start()内部 调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启 动，start()方法才会启动新线程。

#### 50. Java中Runnable和Callable有什么不同？
Runnable和Callable都代表那些要在不同的线程中执行的任务。Runnable从JDK1.0开始就有了，Callable是在 JDK1.5增加的。它们的主要区别是Callable的 call() 方法可以返回值和抛出异常，而Runnable的run()方法没有这些功能。Callable可以返回装载有计算结果的Future对象。

#### 51.Java中CyclicBarrier 和 CountDownLatch有什么不同？
CyclicBarrier 和 CountDownLatch 都可以用来让一组线程等待其它线程。与 CyclicBarrier 不同的是，CountdownLatch 不能重新使用。

#### 52.如何在两个线程间共享数据？
你可以通过共享对象来实现这个目的，或者是使用像阻塞队列这样并发的数据结构。

#### 53.为什么wait, notify 和 notifyAll这些方法不在thread类里面？
这是个设计相关的问题，它考察的是面试者对现有系统和一些普遍存在但看起来不合理的事物的看法。回答这些问题的时候，你要说明为什么把这些方法放在 Object类里是有意义的，还有不把它放在Thread类里的原因。一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通 过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁 就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象

#### 52. 什么是线程安全？Vector是一个线程安全类吗？
如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量 的值也和预期的是一样的，就是线程安全的。一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分 成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的

#### 53.什么是ThreadLocal变量？
ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被 彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因 为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通 过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。线程局部变量的另一个不错的例子是 ThreadLocalRandom类，它在多线程环境中减少了创建代价高昂的Random对象的个数。

#### 54.为什么你应该在循环中检查等待条件?
处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。因此，当一个等待线程醒来 时，不能认为它原来的等待状态仍然是有效的，在notify()方法调用之后和等待线程醒来之前这段时间它可能会改变。这就是在循环中使用wait()方 法效果更好的原因，你可以在Eclipse中创建模板调用wait和notify试一试。如果你想了解更多关于这个问题的内容，我推荐你阅读《Effective Java》这本书中的线程和同步章节。

#### 55.Java中的同步集合与并发集合有什么区别？
同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在Java1.5之前程序员们只有同步集合来用且在 多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分 区等现代技术提高了可扩展性。

#### 56.Java中堆和栈有什么不同？
为什么把这个问题归类在多线程和并发面试题里？因为栈是一块和线程紧密相关的内存区域。每个线程都有自己的栈内存，用于存储本地变量，方法参数和栈 调用，一个线程中存储的变量对其它线程是不可见的。而堆是所有线程共享的一片公用内存区域。对象都在堆里创建，为了提升效率线程会从堆中弄一个缓存到自己 的栈，如果多个线程使用该变量就可能引发问题，这时volatile 变量就可以发挥作用了，它要求线程从主存中读取变量的值。

#### 57.Java中活锁和死锁有什么区别？
这是上题的扩展，活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可以认为是一种特殊的饥饿。一个现实的活锁例子是两个 人在狭小的走廊碰到，两个人都试着避让对方好让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。简单的说就是，活锁和死锁的主要区别是前者 进程的状态可以改变但是却不能继续执行.

#### 58.怎么检测一个线程是否拥有锁？
我一直不知道我们竟然可以检测一个线程是否拥有锁，直到我参加了一次电话面试。在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。

#### 59.JVM中哪个参数是用来控制线程的栈堆栈小的
这个问题很简单， -Xss参数用来控制线程的堆栈大小。

#### 60. Java中synchronized 和 ReentrantLock 有什么不同？
Java在过去很长一段时间只能通过synchronized关键字来实现互斥，它有一些缺点。比如你不能扩展锁之外的方法

#### 61.有三个线程T1，T2，T3，怎么确保它们按顺序执行？
在多线程中有多种方法让线程按特定顺序执行，你可以用线程类的join()方法在一个线程中启动另一个线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个(T3调用T2，T2调用T1)，这样T1就会先完成而T3最后完成。

#### 62.Java中Semaphore是什么？
Java中的Semaphore是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前 会阻塞每一个 acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采 取相应的行动。信号量常常用于多线程的代码中，比如数据库连接池。

#### 63.volatile 变量和 atomic 变量有什么不同？
这是个有趣的问题。首先，volatile 变量和 atomic 变量看起来很像，但功能却不一样。Volatile变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰count变量那么 count++ 操作就不是原子性的。而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性 的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。

#### 64.写出3条你遵循的多线程最佳实践
给你的线程起个有意义的名字。
这样可以方便找bug或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比 Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要框架甚至JDK都遵循这个最佳实践。

避免锁定和缩小同步的范围。
锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。

多用同步类少用wait 和 notify。
首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而用wait和notify很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的JDK中它们还会不断 优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。

多用并发集合少用同步集合。
这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程时使用并发集合效果更好。如果下一次你需要用到map，你应该首先想到用ConcurrentHashMap。

#### 65.Java多线程中调用wait() 和 sleep()方法有什么不同？
Java程序中wait 和 sleep都会造成某种形式的暂停，它们可以满足不同的需要。wait()方法用于线程间通信，如果等待条件为真且其它线程被唤醒时它会释放锁，而 sleep()方法仅仅释放CPU资源或者让当前线程停止执行一段时间，但不会释放锁。

#### 66.java的反射机制

java的反射机制是在运行状态中，对于任意一个类（Class）都能知道他的属性（Field）和方法（Method），对于任意一个对象都能够调用它的方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。它允许正在运行的java程序观测甚至是修改程序的动态行为。

Java中反射有如下几种实现方式：

1、通过Class.forName()方法加载字符串，就可以得到该字符串做代表的Class对象。

2、通过类名调用class属性得到该类的Class对象。

3、调用实例的getClass()方法。

4、如果是基本类型的包装类，则可以通过调用包装类的Type属性来获得该包装类的Class对象。

反射在java中的应用

1、java集成开发环境，每当我们敲入点号时，IDE便会根据点号前的内容，动态展示可以访问的字段和方法。

2、java调试器，它能够在调试过程中枚举某一对象所有字段的值。

3、web开发中，我们经常接触到各种配置的通用框架。为保证框架的可扩展性，他往往借助java的反射机制。例如Spring框架的依赖反转（IOC）便是依赖于反射机制。

#### 67.三大集合接口的引出

Java中的常见集合可以概括如下。

- Map接口和Collection接口是所有集合框架的父接口
- Collection接口的子接口包括：Set接口和List接口
- Map接口的实现类主要有：HashMap、TreeMap、Hashtable、LinkedHashMap、ConcurrentHashMap以及Properties等
- Set接口的实现类主要有：HashSet、TreeSet、LinkedHashSet等
- List接口的实现类主要有：ArrayList、LinkedList、Stack以及Vector等


## 二、C++面试笔记
### C++内容
#### 1.物理内存和虚拟内存
- 每个进程都认为自己独立的享有着计算机的内存
- 虚拟内存：程序运行时，会进行一系列的操作。
进程会构建自己的虚拟地址空间（进程地址空间），该地址空间所有进程都独立的享有一份，如果是32位机器，则会创建2^32（4G）大小的地址空间 ，如果是64位机器，可以创建2^64大小的地址空间（目前所有的程序都没有这么大），创建出来的虚拟地址空间中（以32位机器为例，一般编译器可以选择使用32位或者64位），其中1G为操作系统所用，剩下3G空间为用户所用
- 进程的虚拟地址通过页表访问物理内存，保证了多个进程访问物理内存之间的不冲突性。
- 每次我要访问地址空间上的某一个地址，都需要把地址翻译为实际物理内存地址
- 当每个进程创建的时候，内核会为进程分配4G的虚拟内存，当进程还没有开始运行时，这只是一个内存布局。实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射）。这个时候数据和代码还是在磁盘上的。当运行到对应的程序时，进程去寻找页表，发现页表中地址没有存放在物理内存上，而是在磁盘上，于是发生缺页异常，于是将磁盘上的数据拷贝到物理内存中。
- 在进程运行过程中，要通过malloc来动态分配内存时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。

#### 2.虚拟内存机制的优点
- 在进程运行过程中，要通过malloc来动态分配内存时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。
- 当不同的进程使用同一段代码时，比如库文件的代码，在物理内存中可以只存储一份这样的代码，不同进程只要将自己的虚拟内存映射过去就好了，这样可以节省物理内存
- 在程序需要分配连续空间的时候，只需要在虚拟内存分配连续空间，而不需要物理内存时连续的，实际上，往往物理内存都是断断续续的内存碎片。


#### 3.C++中的堆栈
![](https://img-blog.csdnimg.cn/20191031203641608.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzc5NjY4NQ==,size_16,color_FFFFFF,t_70)
- 栈又叫做堆栈，非静态局部变量/函数参数/返回值等，都在其中存放，栈是向下增长的。
- 内存映射段是装在动静态库，用户使用系统接口创建空想内存的地址区。（本节不详细说明）
- 堆，用于程序运行时动态内存管理分配的区域，与栈区相对，向上增长。
- 数据段是用来存储全局变量和静态数据的区域
- 代码段是用来存储代码的区域。

#### 4.C语言中管理内存的方式
- malloc函数：分配一个大小size字节的内存块，返回指向该块开头的指针。
- alloc函数：分配num个元素组成的内存块，每个元素的大小都是size大小，并将其所有位初始化为零。分配一个(num * size)字节的零初始化内存块
- realloc：先判断当前的指针是否有足够的连续空间，如果有，扩大指针指向的地址，并且将新地址的指针返回，如果空间不够，先按照size指定的大小分配空间，将原有数据从头到尾拷贝到新分配的内存区域，而后释放原来内存区域（注意：原来指针是自动释放，不需要使用free），同时返回新分配的内存区域的首地址。即重新分配存储器块的地址
- free：简单来说，释放一个指针所指向的空间

#### 5.free()与delete的区别
- 1、new/delete是C++的操作符，而malloc/free是C中的函数。
- 2、new做两件事，一是分配内存，二是调用类的构造函数；同样，delete会调用类的析构函数和释放内存。而malloc和free只是分配和释放内存。

- 3、new建立的是一个对象，而malloc分配的是一块内存；new建立的对象可以用成员函数访问，不要直接访问它的地址空间；malloc分配的是一块内存区域，用指针访问，可以在里面移动指针；new出来的指针是带有类型信息的，而malloc返回的是void指针。

- 4、new/delete是保留字，不需要头文件支持；malloc/free需要头文件库函数支持

#### 6.进程和程序的区别和联系
- 1、进程是动态的，而程序是静态的。
- 2、进程有一定的生命期，而程序是指令的集合，本身无“运动”的含义。没有建立进程的程序不能作为1个独立单位得到操作系统的认可。
- 3、1个程序可以对应多个进程，但1个进程只能对应1个程序。进程和程序的关系犹如演出和剧本的关系。
- 4、进程和程序的组成不同。从静态角度看，进程由程序、数据和进程控制块（PCB）三部分组成。而程序是一组有序的指令集合

#### 7.static关键字的作用
- 对于函数定义和代码块之外的变量声明，static修改标识符的链接属性，由默认的external变为internal，作用域和存储类型不改变，这些符号只能在声明它们的源文件中访问。
- 对于代码块内部的变量声明，static修改标识符的存储类型，由自动变量改为静态变量，作用域和链接属性不变。这种变量在程序执行之前就创建，在程序执行的整个周期都存在。

- 对于被static修饰的普通函数，其只能在定义它的源文件中使用，不能在其他源文件中被引用

- 对于被static修饰的类成员变量和成员函数，它们是属于类的，而不是某个对象，所有对象共享一个静态成员。静态成员通过<类名>::<静态成员>来使用。一样，它们都属于类的静态成员，它们都不是对象成员。

#### 8.C++和C的区别
设计思想上：
- C++是面向对象的语言，而C是面向过程的结构化编程语言

语法上：

- C++具有封装、继承和多态三种特性

- C++相比C，增加多许多类型安全的功能，比如强制类型转换、

- C++支持范式编程，比如模板类、函数模板等

#### 9.C++中四种cast转换
- 1、const_cast:用于将const变量转为非const
- 2、static_cast: 用于各种隐式转换， 比如非const转const，void*转指针等, static_cast能用于多态向上转化，如果向下转能成功但是不安全，结果未知；
- dynamic_cast:用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常
- reinterpret_cast:几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用；
- 为什么不使用C的强制转换？
C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。

#### 10.C/C++ 中指针和引用的区别？
- 1.指针有自己的一块空间，而引用只是一个别名；
- 2.使用sizeof看一个指针的大小是4，而引用则是被引用对象的大小；

- 3.指针可以被初始化为NULL，而引用必须被初始化且必须是一个已有对象 的引用；

- 4.作为参数传递时，指针需要被解引用才可以对对象进行操作，而直接对引 用的修改都会改变引用所指向的对象；

- 5.可以有const指针，但是没有const引用；

- 6.指针在使用中可以指向其它对象，但是引用只能是一个对象的引用，不能 被改变；

- 7.指针可以有多级指针（**p），而引用只有一级；

- 8.指针和引用使用++运算符的意义不一样；

- 9.如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄露。

#### 11.数组和指针的区别
- 指针：保存数据的地址。间接访问数据，首先获得指针的内容，然后将其作为地址，从该地址中提取数据。通常用于动态的数据结构。通过Malloc分配内存，free释放内存。通常指向匿名数据，操作匿名函数
- 保存数据。直接访问数据。通常用于固定数目且数据类型相同的元素。隐式的分配和删除。自身即为数据名。

#### 12.野指针
- 野指针就是指向一个已删除的对象或者未申请访问受限内存区域的指针


#### 13.C++中的智能指针
- 智能指针主要用于管理在堆上分配的内存，它将普通的指针封装为一个栈对象。当栈对象的生存周期结束后，会在析构函数中释放掉申请的内存，从而防止内存泄漏。
- 最常用的智能指针类型为shared_ptr,它采用引用计数的方法，记录当前内存资源被多少个智能指针引用。该引用计数的内存在堆上分配
- 对shared_ptr进行初始化时不能将一个普通指针直接赋值给智能指针，因为一个是指针，一个是类。可以通过make_shared函数或者通过构造函数传入普通指针。
- 并可以通过get函数获得普通指针。

#### 14.智能指针有没有内存泄露的情况
- 当两个对象相互使用一个shared_ptr成员变量指向对方，会造成循环引用，使引用计数失效，从而导致内存泄漏。
- 智能指针的内存泄漏如何解决
```
为了解决循环引用导致的内存泄漏，引入了weak_ptr弱指针，weak_ptr的构造函数不会修改引用计数的值，从
而不会对对象的内存进行管理，其类似一个普通指针，但不指向引用计数的共享内存，但是其可以检测到所管
理的对象是否已经被释放，从而避免非法访问。
```

#### 15.C++中析构函数的作用
- 析构函数与构造函数对应，当对象结束其生命周期，如对象所在的函数已调用完毕时，系统会自动执行析构函数。
- 析构函数名也应与类名相同，只是在函数名前面加一个位取反符，例如stud( )，以区别于构造函数。它不能带任何参数，也没有返回值（包括void类型）。只能有一个析构函数，不能重载。
- 类析构顺序：1）派生类本身的析构函数；2）对象成员析构函数；3）基类析构函数。

#### 16.C++中虚函数的作用和多态
- C++中的虚函数的作用主要是实现了多态的机制。基类定义虚函数，子类可以重写该函数；在派生类中对基类定义的虚函数进行重写时，需要在派生类中声明该方法为虚方法。
- 当子类重新定义了父类的虚函数后，当父类的指针指向子类对象的地址时，[即B b; A a = &b;] 父类指针根据赋给它的不同子类指针，动态的调用子类的该函数，而不是父类的函数（如果不使用virtual方法，请看后面★*），且这样的函数调用发生在运行阶段，而不是发生在编译阶段，称为动态联编。
- 多态的实现主要分为静态多态和动态多态，静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定。

#### 17.虚函数的底层实现机制
- 编译器处理虚函数的方法是：为每个类对象添加一个隐藏成员，隐藏成员中保存了一个指向函数地址数组的指针，称为虚表指针（vptr），这种数组成为虚函数表（virtual function table, vtbl），即，每个类使用一个虚函数表，每个类对象用一个虚表指针。
- 虚函数的实现：在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。

#### 18.为什么父类的析构函数必须是虚函数？为什么C++默认的析构函数不是虚函数
- 将可能会被继承的父类的析构函数设置为虚函数，可以保证当我们new一个子类，然后使用基类指针指向该子类对象，释放基类指针时可以释放掉子类的空间，防止内存泄漏。

- C ++ 默认的析构函数不是虚函数是因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。而对于不会被继承的类来说，其析构函数如果是虚函数，就会浪费内存。因此C++默认的析构函数不是虚函数，而是只有当需要当作父类时，设置为虚函数。

#### 19.函数指针
- 函数指针是指向函数的指针变量。
- C在编译时，每一个函数都有一个入口地址，该入口地址就是函数指针所指向的地址。

#### 20.fork函数
- 成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。
- 在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。
- 最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。
- Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

#### 21.静态函数和虚函数的区别
参考回答：
- 静态函数在编译的时候就已经确定运行时机，虚函数在运行的时候动态绑定。
- 虚函数因为用了虚函数表机制，调用的时候会增加一次内存开销

#### 22.strcpy和strlen
- strcpy是字符串拷贝函数，原型：
char *strcpy(char* dest, const char *src);从src逐字节拷贝到dest，直到遇到'\0'结束，因为没有指定长度，可能会导致拷贝越界，造成缓冲区溢出漏洞,安全版本是strncpy函数。
- strlen函数是计算字符串长度的函数，返回从开始到'\0'之间的字符个数。

#### 23.请你来写个函数在main函数执行前先运行
__attribute((constructor))是gcc扩展，标记这个函数应当在main函数之前执行。
```
__attribute((constructor))void before()
{
    printf("before main\n");
}
```

#### 24.以下四行代码的区别是什么？ const char * arr = "123"; char * brr = "123"; const char crr[] = "123"; char drr[] = "123";
```
const char * arr = "123";
//字符串123保存在常量区，const本来是修饰arr指向的值不能通过arr去修改，但是字符串“123”在常量区，本来就不能改变，所以加不加const效果都一样
```
```
char * brr = "123";

//字符串123保存在常量区，这个arr指针指向的是同一个位置，同样不能通过brr去修改"123"的值
```
```
const char crr[] = "123";

//这里123本来是在栈上的，但是编译器可能会做某些优化，将其放到常量区
```
```
char drr[] = "123";

//字符串123保存在栈区，可以通过drr去修改
```

#### 25.C++里是怎么定义常量的？常量存放在内存的哪个位置？
- 常量在C++里的定义就是一个top-level const加上对象类型，常量定义必须初始化。
- 对于局部对象，常量存放在栈区，对于全局对象，常量存放在全局/静态存储区。
- 对于字面值常量，常量存放在常量存储区

#### 26.如果同时定义了两个函数，一个带const，一个不带，会有问题吗？
- 不会，这相当于函数的重载。

#### 27.C++函数栈空间的最大值
默认是1M，不过可以调整

#### 28.说一说extern“C”
- C++调用C函数需要extern C，因为C语言没有函数重载。

#### 29.隐式类型转换
- 首先，对于内置类型，低精度的变量给高精度变量赋值会发生隐式类型转换。
- 其次，对于只存在单个参数的构造函数的对象构造来说，函数调用可以直接使用该参数传入，编译器会自动调用其构造函数生成临时对象。

#### 30.RTTI是什么
- RTTI 是“Runtime Type Information”的缩写，意思是：运行时类型信息。它提供了运行时确定对象类型的方法。
- 两个重要的 RTTI 运算符的使用方法，它们是 typeid 和 dynamic_cast。
- typeid的主要作用就是让用户知道当前的变量是什么类型的，对于内置数据类型以及自定义数据类型都生效
- dynamic_cast主要用于在多态的时候，它允许在运行时刻进行类型转换，从而使程序能够在一个类层次结构中安全地转换类型，把基类指针（引用）转换为派生类指针（引用）

#### 31.虚函数表具体是怎样实现运行时多态的?
- 子类若重写父类虚函数，虚函数表中，该函数的地址会被替换；
- 对于存在虚函数的类的对象，在VS中，对象的对象模型的头部存放指向虚函数表的指针，通过该机制实现多态。

#### 32.C语言是怎么进行函数调用的？
- 每一个函数调用都会分配函数栈，在栈内进行函数执行过程。
- 调用前，先把返回地址压栈，然后把当前函数的esp指针压栈

#### 33.C语言参数压栈顺序？
从右到左

#### 34.C++如何处理返回值？
- 生成一个临时变量，把它的引用作为函数参数传入函数内。

#### 35.C++中拷贝赋值函数的形参能否进行值传递？
- 不能。如果是这种情况下，调用拷贝构造函数的时候，首先要将实参传递给形参，这个传递的时候又要调用拷贝构造函数。。如此循环，无法完成拷贝，栈也会满。

#### 36.fork,wait,exec函数
- 父进程产生子进程使用fork拷贝出来一个父进程的副本，此时只拷贝了父进程的页表，两个进程都读同一块内存，当有进程写的时候使用写实拷贝机制分配内存，exec函数可以加载一个elf文件去替换父进程，从此父进程和子进程就可以运行不同的程序了。
- fork从父进程返回子进程的pid，从子进程返回0.调用了wait的父进程将会发生阻塞，直到有子进程状态改变,执行成功返回0，错误返回-1。
- exec执行成功则子进程从新的程序开始运行，无返回值，执行失败返回-1

#### 37.C++中struct和class的区别
- 在C++中，可以用struct和class定义类，都可以继承。区别在于：structural的默认继承权限和默认访问权限是public，而class的默认继承权限和默认访问权限是private。
- class还可以定义模板类形参，比如template <class T, int i>。

#### 38.什么是右值引用，跟左值又有什么区别？
- 右值引用是C++11中引入的新特性 , 它实现了转移语义和精确传递。它的主要目的有两个方面：
```
1. 消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率。

2. 能够更简洁明确地定义泛型函数。
```
- 左值和右值的概念：
```
左值：能对表达式取地址、或具名对象/变量。一般指表达式结束后依然存在的持久对象。

右值：不能对表达式取地址，或匿名对象。一般指表达式结束就不再存在的临时对象。
```
- 右值引用和左值引用的区别：
```
1. 左值可以寻址，而右值不可以。

2. 左值可以被赋值，右值不可以被赋值，可以用来给左值赋值。

3. 左值可变,右值不可变（仅对基础类型适用，用户自定义类型右值引用可以通过成员函数改变）。
```

#### 39.静态变量什么时候初始化
- 静态变量存储在虚拟地址空间的数据段和bss段
- C语言中其在代码执行之前初始化，属于编译期初始化。
- 而C ++ 中由于引入对象，对象生成必须调用构造函数，因此C++规定全局或局部静态对象当且仅当对象首次用到时进行构造

### 容器STL
#### 1.stl里面set和map怎么实现的?
- 集合，所有元素都会根据元素的值自动被排序，且不允许重复。
```
底层实现：红黑树

set 底层是通过红黑树（RB-tree）来实现的，由于红黑树是一种平衡二叉搜索树，自动排序的效果很不错，所以标准的 STL 的 set 即以 RB-Tree 为底层机制。又由于 set 所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 set 操作行为，都只有转调用 RB-tree 的操作行为而已。

适用场景：有序不重复集合
```
- 映射。map 的所有元素都是 pair，同时拥有实值（value）和键值（key）。
```
pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。不允许键值重复。

底层：红黑树

适用场景：有序键值对不重复映射
```
#### 2.STL中map与unordered_map
1、Map映射，map 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。不允许键值重复。

底层实现：红黑树

适用场景：有序键值对不重复映射

2、Multimap多重映射。multimap 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。允许键值重复。

底层实现：红黑树

适用场景：有序键值对可重复映射


#### 3.vector和list的区别，应用
- 1vector底层实现是数组；list是双向 链表。

- 2）vector支持随机访问，list不支持。

- 3）vector是顺序内存，list不是。

- 4）vector在中间节点进行插入删除会导致内存拷贝，list不会。

- 5）vector一次性分配好内存，不够时才进行2倍扩容；list每次插入新节点都会进行内存申请。

- 6）vector随机访问性能好，插入删除性能差；list随机访问性能差，插入删除性能好。

应用

- vector拥有一段连续的内存空间，因此支持随机访问，如果需要高效的随即访问，而不在乎插入和删除的效率，使用vector。

- list拥有一段不连续的内存空间，如果需要高效的插入和删除，而不关心随机访问，则应使用list。

#### 4.STL迭代器是怎么删除元素的呢
- 1.对于序列容器vector,deque来说，使用erase(itertor)后，后边的每个元素的迭代器都会失效，但是后边每个元素都会往前移动一个位置，但是erase会返回下一个有效的迭代器；

- 2.对于关联容器map set来说，使用了erase(iterator)后，当前元素的迭代器失效，但是其结构是红黑树，删除当前元素的，不会影响到下一个元素的迭代器，所以在调用erase之前，记录下一个元素的迭代器即可。

- 3.对于list来说，它使用了不连续分配的内存，并且它的erase方法也会返回下一个有效的iterator，因此上面两种正确的方法都可以使用。

#### 5.STL中迭代器的作用，有指针为何还要迭代器?
- 迭代器不是指针，是类模板，表现的像指针。他只是模拟了指针的一些功能，通过重载了指针的一些操作符，->、*、++、--等。
- 迭代器返回的是对象引用而不是对象的值，所以cout只能输出迭代器使用*取值后的值而不能直接输出其自身。

迭代器产生原因
- Iterator类的访问方式就是把不同集合类的访问逻辑抽象出来，使得不用暴露集合内部的结构而达到循环遍历集合的效果。

#### 6.STL里resize和reserve的区别
- resize()：改变当前容器内含有元素的数量(size())，eg: vector<int>v; v.resize(len);v的size变为len,如果原来v的size小于len，那么容器新增（len-size）个元素，元素的值为默认为0.当v.push_back(3);之后，则是3是放在了v的末尾，即下标为len，此时容器是size为len+1；
- reserve()：改变当前容器的最大容量（capacity）,它不会生成元素，只是确定这个容器允许放入多少对象，如果reserve(len)的值大于当前的capacity()，那么会重新分配一块能存len个对象的空间，然后把之前v.size()个对象通过copy construtor复制过来，销毁之前的内存；

### 编译与底层
#### 1.一个C++源文件从文本到可执行文件经历的过程？
- 预处理阶段：对源代码文件中文件包含关系（头文件）、预编译语句（宏定义）进行分析和替换，生成预编译文件。

- 编译阶段：将经过预处理后的预编译文件转换成特定汇编代码，生成汇编文件

- 汇编阶段：将编译阶段生成的汇编文件转化成机器码，生成可重定位目标文件

- 链接阶段：将多个目标文件及所需要的库连接成最终的可执行目标文件

#### 2.include头文件的顺序
- 对于include的头文件来说，如果在文件a.h中声明一个在文件b.h中定义的变量，而不引用b.h。那么要在a.c文件中引用b.h文件，并且要先引用b.h，后引用a.h,否则汇报变量类型未声明错误。

#### 3.双引号””和尖括号<>的区别？
- 双引号和尖括号的区别：编译器预处理阶段查找头文件的路径不一样。
- 双引号包含的头文件，查找头文件路径的顺序为：
1）.当前头文件目录；2）编译器设置的头文件路径（编译器可使用-I显式指定搜索路径）;3)系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径

- 尖括号包含的头文件，查找头文件的路径顺序为：
1)编译器设置的头文件路径（编译器可使用-I显式指定搜索路径）;2)系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径

#### 4.malloc的原理
- Malloc函数用于动态分配内存。
- 为了减少内存碎片和系统调用的开销，malloc其采用内存池的方式，先申请大块内存作为堆区，然后将堆区分为多个内存块，以块作为内存管理的基本单位。
- 当用户申请内存时，直接从堆区分配一块合适的空闲块。Malloc采用隐式链表结构将堆区分成连续的、大小不一的块，包含已分配块和未分配块；同时malloc采用显示链表结构来管理所有的空闲块，即使用一个双向链表将空闲块连接起来，每一个空闲块记录了一个连续的、未分配的地址。

#### 5.brk系统调用和mmap系统调用的作用分别是什么？
- Malloc在申请内存时，一般会通过brk或者mmap系统调用进行申请。其中当申请内存小于128K时，会使用系统函数brk在堆区中分配；而当申请内存大于128K时，会使用系统函数mmap在映射区分配。

#### 6.C++的内存管理是怎样的？
在C++中，虚拟内存分为代码段、数据段、BSS段、堆区、文件映射区以及栈区六部分。

- 代码段:包括只读存储区和文本区，其中只读存储区存储字符串常量，文本区存储程序的机器代码。

- 数据段：存储程序中已初始化的全局变量和静态变量

- bss 段：存储未初始化的全局变量和静态变量（局部+全局），以及所有被初始化为0的全局变量和静态变量。

- 堆区：调用new/malloc函数时在堆区动态分配内存，同时需要调用delete/free来手动释放申请的内存。

- 映射区:存储动态链接库以及调用mmap函数进行的文件映射

- 栈：使用栈空间存储函数的返回地址、参数、局部变量、返回值

#### 7.如何判断内存泄漏？
- 内存泄漏通常是由于调用了malloc/new等内存申请的操作，但是缺少了对应的free/delete。 
- 为了判断内存是否泄露，我们一方面可以使用linux环境下的内存泄漏检查工具Valgrind
- 另一方面我们在写代码时可以添加内存申请和释放的统计功能，统计当前申请和释放的内存是否一致，以此来判断内存是否泄露。

#### 8.什么时候会发生段错误
- 段错误通常发生在访问非法内存地址的时候
- 使用野指针
- 试图修改字符串常量的内容

#### 9.memory leak，也就是内存泄漏
- 内存泄漏(memory leak)是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。
- 内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。
- 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak.
- 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
- 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。

#### 10.说一下共享内存相关api

1）新建共享内存shmget
```
int shmget(key_t key,size_t size,int shmflg);

key：共享内存键值，可以理解为共享内存的唯一性标记。

size：共享内存大小

shmflag：创建进程和其他进程的读写权限标识。

返回值：相应的共享内存标识符，失败返回-1
```

2）连接共享内存到当前进程的地址空间shmat
```
void *shmat(int shm_id,const void *shm_addr,int shmflg);

shm_id：共享内存标识符

shm_addr：指定共享内存连接到当前进程的地址，通常为0，表示由系统来选择。

shmflg：标志位

返回值：指向共享内存第一个字节的指针，失败返回-1
```

3）当前进程分离共享内存shmdt
```
int shmdt(const void *shmaddr);
```

4）控制共享内存shmctl
```
和信号量的semctl函数类似，控制共享内存

int shmctl(int shm_id,int command,struct shmid_ds *buf);

shm_id：共享内存标识符

command: 有三个值

IPC_STAT:获取共享内存的状态，把共享内存的shmid_ds结构复制到buf中。

IPC_SET:设置共享内存的状态，把buf复制到共享内存的shmid_ds结构。

IPC_RMID:删除共享内存

buf：共享内存管理结构体。
```
#### 11.如何采用单线程的方式处理高并发
- 在单线程模型中，可以采用I/O复用来提高单线程处理多个请求的能力
- 然后再采用事件驱动模型
- 基于异步回调来处理事件来

#### 12.C++如何处理内存泄漏？
- 使用varglind，mtrace检测

### C++11特性
#### 1.C++11 最常用的新特性如下：
- auto关键字：编译器可以根据初始值自动推导出类型。但是不能用于函数传参以及数组类型的推导

- nullptr关键字：nullptr是一种特殊类型的字面值，它可以被转换成任意其它的指针类型；而NULL一般被宏定义为0，在遇到重载时可能会出现问题。

- 智能指针：C++11新增了std::shared_ptr、std::weak_ptr等类型的智能指针，用于解决内存管理的问题。

- 初始化列表：使用初始化列表来对类进行初始化

- 右值引用：基于右值引用可以实现移动语义和完美转发，消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率

- atomic原子操作用于多线程资源互斥操作

- 新增STL容器array以及tuple

## 三、操作系统
### 常见问题
#### 1.进程与线程的概念
- 进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；
- 线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。
- 每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。

两者区别

- 1.一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。
- 2.进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。
- 3.进程是资源分配的最小单位，线程是CPU调度的最小单位；
- 4.系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。
- 5.进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。

- 6.进程间不会相互影响 ；一个线程挂掉将导致整个进程挂掉

- 7.进程适应于多核、多机分布；线程适用于多核


#### 2.进程间通信的方式
进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。

- 管道

```
管道主要包括无名管道和命名管道 :管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信
```
```
1.1 普通管道PIPE：

1)它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端

2)它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）

3)它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

1.2 命名管道FIFO：

1)FIFO可以在无关的进程之间交换数据

2)FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。
```
- 系统IPC
```
2.1 消息队列

消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 (消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

特点：

1)消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。

2)消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。

3)消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。
```

```
2.2 信号量semaphore

信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

特点：

1)信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

2)信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

3)每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

4)支持信号量组。
```

```
2.3 信号signal

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
```

```
2.4 共享内存（Shared Memory）

它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等

特点：

1)共享内存是最快的一种IPC，因为进程是直接对内存进行存取

2)因为多个进程可以同时操作，所以需要进行同步

3)信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问

```
- 套接字SOCKET
```
socket也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。
```

#### 3.线程间通信的方式
```
临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；

互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。

事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作
```

#### 4.虚拟内存的好处
```
1.扩大地址空间；

2.内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。

3.公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。

4.当进程通信时，可采用虚存共享的方式实现。

5.当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存

6.虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高

7.在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片
```

#### 5.虚拟内存的代价
```
1.虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存

2.虚拟地址到物理地址的转换，增加了指令的执行时间。

3.页面的换入换出需要磁盘I/O，这是很耗时的

4.如果一页中只有一部分数据，会浪费内存。
```
缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：
```
1、在指令执行期间产生和处理缺页中断信号

2、一条指令在执行期间，可能产生多次缺页中断

3、缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。
```
#### 6.操作系统中的缺页中断
- malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。
- 缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：
```
1、保护CPU现场

2、分析中断原因

3、转入缺页中断处理程序进行处理

4、恢复CPU现场，继续执行
```

#### 7.fork和vfork的区别

```
1. fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段

2. fork( )的父子进程的执行次序不确定；vfork( )保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。

3. vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。

4.当需要改变共享数据段中变量的值，则拷贝父进程。
```

#### 8.请问如何修改文件最大句柄数？
- linux默认最大文件句柄数是1024个，在linux服务器文件并发量比较大的情况下，系统会报"too many open files"的错误。
-  ulimit -n <可以同时打开的文件数>，将当前进程的最大句柄数修改为指定的参数(该方法只针对当前进程有效，重新打开一个shell或者重新开启一个进程，参数还是之前的值)
-  ulimit -a查询Linux相关的参数

对所有进程都有效的方法，修改Linux系统参数
```
vi /etc/security/limits.conf 添加

*　　soft　　nofile　　65536

*　　hard　　nofile　　65536

将最大句柄数改为65536
```
修改以后保存，注销当前用户，重新登录，修改后的参数就生效了

#### 9.并发(concurrency)和并行(parallelism)

- 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。

- 并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。

#### 10.MySQL的端口号是多少，如何修改这个端口号
- mysql的默认端口是3306。
- 编辑/etc/my.cnf文件，早期版本有可能是my.conf文件名，增加端口参数，并且设定端口，注意该端口未被使用，保存退出。

#### 11.操作系统中的页表寻址
- 页式内存管理，内存分成固定长度的一个个页片。操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表.
- 页表的内容就是该进程的虚拟地址到物理地址的一个映射。页表中的每一项都记录了这个页的基地址。
- 通过页表，由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移一定长度就得到最后的物理地址，偏移的长度由逻辑地址的低位部分决定。
- 一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。

#### 12.请问单核机器上写多线程程序，是否需要考虑加锁，为什么？
- 在单核机器上写多线程程序，仍然需要线程锁。因为线程锁通常用来实现线程的同步和通信。
- 在单核机器上的多线程程序，仍然存在线程同步的问题。
- 因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。
- 如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。

#### 13.线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的
线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息。
```
SP:堆栈指针，指向当前栈的栈顶地址

PC:程序计数器，存储下一条将要执行的指令

EAX:累加寄存器，用于加法乘法的缺省寄存器
```

#### 14.线程间的同步方式，最好说出具体的系统调用
- 信号量
```
信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：

P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。

V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。

其系统调用为：

sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。

sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。
```
- 互斥量
```
互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区      时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。其主要的系统调用如下：

pthread_mutex_init:初始化互斥锁

pthread_mutex_destroy：销毁互斥锁

pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。

pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁。
```
- 条件变量
```
条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。其主要的系统调用如下：

pthread_cond_init：初始化条件变量

pthread_cond_destroy：销毁条件变量

pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。

pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。
```
#### 15.多线程和多进程的不同
- 进程是资源分配的最小单位，而线程时CPU调度的最小单位。
- 多线程之间共享同一个进程的地址空间，线程间通信简单，同步复杂，线程创建、销毁和切换简单，速度快，占用内存少，适用于多核分布式系统，但是线程间会相互影响，一个线程意外终止会导致同一个进程的其他线程也终止，程序可靠性弱。
- 多进程间拥有各自独立的运行地址空间，进程间不会相互影响，程序可靠性强，但是进程创建、销毁和切换复杂，速度慢，占用内存多，进程间通信复杂，但是同步简单，适用于多核、多机分布。

#### 16.游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么？
- 游戏服务器应该为每个用户开辟一个进程。因为同一进程间的线程会相互影响，一个线程死掉会影响其他线程，从而导致进程崩溃。因此为了保证不同用户之间不会相互影响，应该为每个用户开辟一个进程

#### 17.OS缺页置换算法
当前操作系统最常采用的缺页置换算法如下：
```
1、FIFO（先进先出淘汰算法）

思想：最近刚访问的，将来访问的可能性比较大。

实现：使用一个队列，新加入的页面放入队尾，每次淘汰队首的页面，即最先进入的数据，最先被淘汰。

弊端：无法体现页面冷热信息
```
```
2、LFU（最不经常访问淘汰算法）

思想：如果数据过去被访问多次，那么将来被访问的频率也更高。

实现：每个数据块一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。每次淘汰队尾数据块。

开销：排序开销。

弊端：缓存颠簸。
```
```
3、LRU（最近最少使用替换算法）

思想：如果数据最近被访问过，那么将来被访问的几率也更高。

实现：使用一个栈，新页面或者命中的页面则将该页面移动到栈底，每次替换栈顶的缓存页面。

优点：LRU算法对热点数据命中率是很高的。

缺陷：

1）缓存颠簸，当缓存（1，2，3）满了，之后数据访问（0，3，2，1，0，3，2，1。。。）。

2）缓存污染，突然大量偶发性的数据访问，会让内存中存放大量冷数据。
```
```
4、LRU-K（LRU-2、LRU-3）

思想：最久未使用K次淘汰算法。

LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。

相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。

实现：

1）数据第一次被访问，加入到访问历史列表；

2）如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰；

3）当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序；

4）缓存数据队列中被再次访问后，重新排序；

5）需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。

针对问题：

LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。
```
```
5、2Q

类似LRU-2。使用一个FIFO队列和一个LRU队列。

实现：

1）新访问的数据插入到FIFO队列；

2）如果数据在FIFO队列中一直没有被再次访问，则最终按照FIFO规则淘汰；

3）如果数据在FIFO队列中被再次访问，则将数据移到LRU队列头部；

4）如果数据在LRU队列再次被访问，则将数据移到LRU队列头部；

5）LRU队列淘汰末尾的数据。

针对问题：LRU的缓存污染

弊端：

当FIFO容量为2时，访问负载是：ABCABCABC会退化为FIFO，用不到LRU。
```
#### 18.作系统中的结构体对齐，字节对齐
```
1、原因：
1）平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。

2）性能原因：数据结构（尤其是栈）应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。

2、规则

1）数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员的对齐按照#pragma pack指定的数值和这个数据成员自身长度中，比较小的那个进行。

2）结构(或联合)的整体对齐规则：在数据成员完成各自对齐之后，结构(或联合)本身也要进行对齐，对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行。

3）结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。

3、定义结构体对齐

可以通过预编译命令#pragma pack(n)，n=1,2,4,8,16来改变这一系数，其中的n就是指定的“对齐系数”。

4、举例

#pragma pack(2)

struct AA {

int a;       //长度4 > 2 按2对齐；偏移量为0；存放位置区间[0,3]

char b;  //长度1 < 2 按1对齐；偏移量为4；存放位置区间[4]

short c;     //长度2 = 2 按2对齐；偏移量要提升到2的倍数6；存放位置区间[6,7]

char d;  //长度1 < 2 按1对齐；偏移量为7；存放位置区间[8]；共九个字节

};

#pragma pack()
```

#### 19.多进程和多线程的使用场景
- 多进程模型的优势是CPU
- 多线程模型主要优势为线程间切换代价较小，因此适用于I/O密集型的工作场景，因此I/O密集型的工作场景经常会由于I/O阻塞导致频繁的切换线程。同时，多线程模型也适用于单机多核分布式场景。
- 多进程模型，适用于CPU密集型。同时，多进程模型也适用于多机分布式场景中，易于多机扩展。

#### 20.互斥锁和读写锁的区别
概念

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

- 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

互斥锁和读写锁的区别：
```
1）读写锁区分读者和写者，而互斥锁不区分

2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。
```
#### 21.Linux的4种锁机制：
```
互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒
```
```
读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线
程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于
读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。
```
```
自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠
，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂
的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。
```
```
RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update成新的数据。使用RCU时
，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制
被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。
```
#### 22.进程状态转换图
![](https://uploadfiles.nowcoder.com/images/20190313/311436_1552470678794_F9BF116BD97A95A5E655DF9E1672186F)
```
1）创建状态：进程正在被创建

2）就绪状态：进程被加入到就绪队列中等待CPU调度运行

3）执行状态：进程正在被运行

4）等待阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行。

5）终止状态：进程运行完毕
```
```
1）活动阻塞：进程在内存，但是由于某种原因被阻塞了。

2）静止阻塞：进程在外存，同时被某种原因阻塞了。

3）活动就绪：进程在内存，处于就绪状态，只要给CPU和调度就可以直接运行。

4）静止就绪：进程在外存，处于就绪状态，只要调度到内存，给CPU和调度就可以运行。
```
交换技术
```
当多个进程竞争内存资源时，会造成内存资源紧张，并且，如果此时没有就绪进程，处理机会空闲，I/0速
度比处理机速度慢得多，可能出现全部进程阻塞等待I/O。
```
针对以上问题，提出了两种解决方法：
```
1）交换技术：换出一部分进程到外存，腾出内存空间。
2）虚拟存储技术：每个进程只能装入一部分程序和数据。
```
```
在交换技术上，将内存暂时不能运行的进程，或者暂时不用的数据和程序，换出到外存，来腾出足够的内
存空间，把已经具备运行条件的进程，或进程所需的数据和程序换入到内存。
```
#### 23.A* a = new A; a->i = 10;在内核中的内存分配上发生了什么？
```
1）A *a：a是一个局部变量，类型为指针，故而操作系统在程序栈区开辟4/8字节的空间（0x000m），分配给指针a。

2）new A：通过new动态的在堆区申请类A大小的空间（0x000n）。

3）a = new A：将指针a的内存区域填入栈中类A申请到的地址的地址。即*（0x000m）=0x000n。

4）a->i：先找到指针a的地址0x000m，通过a的值0x000n和i在类a中偏移offset，得到a->i的地址0x000n + offset，进行*(0x000n + offset) = 
10的赋值操作，即内存0x000n + offset的值是10。
```

#### 24.用户态和内核态区别
- 用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。
- 用户态拥有最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据结构和程序。
- 内核态和用户态之间的转换方式主要包括：系统调用，异常和中断。

#### 25.死循环+来连接时新建线程的方法效率有点低，怎么改进？
提前创建好一个线程池，用生产者消费者模型，创建一个任务队列，队列作为临界资源，有了新连接，就挂在到任务队列上，队列为空所有线程睡眠。改进死循环：使用select epoll这样的技术

#### 26.怎样确定当前线程是繁忙还是阻塞？
使用ps命令查看

#### 27.请问就绪状态的进程在等待什么？
被调度使用cpu的运行权

#### 28.两个进程访问临界区资源，会不会出现都获得自旋锁的情况？
单核cpu，并且开了抢占可以造成这种情况。

#### 29.windows消息机制知道吗
当用户有操作(鼠标，键盘等)时，系统会将这些时间转化为消息。每个打开的进程系统都为其维护了一个消息队列，系统会将这些消息放到进程的消息队列中，而应用程序会循环从消息队列中取出来消息，完成对应的操作

#### 30.请你说一说死锁产生的必要条件？
```
1.互斥条件：一个资源每次只能被一个进程使用。
2.请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3.不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。
4.循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。
```

#### 31.内存溢出和内存泄漏
1、内存溢出
```
指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误
```
内存溢出原因：
```
1).内存中加载的数据量过于庞大，如一次从数据库取出过多数据

2).集合类中有对对象的引用，使用完后未清空，使得不能回收

3).代码中存在死循环或循环产生过多重复的对象实体

4).使用的第三方软件中的BUG

5).启动参数内存值设定的过小
```
2、内存泄漏
```
内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理
上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。
```
内存泄漏的分类：
```
1、堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc 
new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 
删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。
```
```
2、系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle 
,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
```
```
3、没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，
那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。
```
#### 32.常用线程模型

1、Future模型
```
该模型通常在使用的时候需要结合Callable接口配合使用。

Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。

Callable是类似于Runnable的接口，其中call方法类似于run方法，所不同的是run方法不能抛出受检异常没有返回值，而call方法则可以抛出受检异常并可设置返回值。两者的方法体都是线程执行体。
```
2、fork&join模型

```
该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子
任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果。

这里模拟一个摘苹果的场景：有100棵苹果树，每棵苹果树有10个苹果，现在要把他们摘下来。为了节约时
间，规定每个线程最多只能摘10棵苹树以便于节约时间。各个线程摘完之后汇总计算总苹果树。
```
3、actor模型
```
actor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继
续传递（分发）给其它actor进行处理。在使用actor模型的时候需要使用第三方Akka提供的框架。
```

4、生产者消费者模型
```
生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后
再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费
者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活
的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题。
```

5、master-worker模型
```
master-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处
理任务。如需返回结果，则worker处理结束之后把处理结果返回给master。
```

#### 33.协程与线程的区别
- 协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。
- 那和多线程比，协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。

- 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

#### 34.系统调用是什么，你用过哪些系统调用
- 系统调用（英语：system call），又称为系统呼叫，指运行在使用者空间的程序向操作系统内核请求需要更高权限运行的服务。
- 操作系统中的状态分为管态（核心态）和目态（用户态）。大多数系统交互式操作需求在内核态执行。
- 特权指令：一类只能在核心态下运行而不能在用户态下运行的特殊指令。
- 应用程序有时会需要一些危险的、权限很高的指令，如果把这些权限放心地交给用户程序是很危险的(比如一个进程可能修改另一个进程的内存区，导致其不能运行)，但是又不能完全不给这些权限。于是有了系统调用，危险的指令被包装成系统调用，用户程序只能调用而无权自己运行那些危险的指令。
- 计算机硬件的资源是有限的，为了更好的管理这些资源，所有的资源都由操作系统控制，进程只能向操作系统请求这些资源。
- 操作系统是这些资源的唯一入口，这个入口就是系统调用。

写数据write，创建进程fork，vfork等都是系统调用。
#### 35.手写一下fork调用示例
```
int main(void)
{
    pid_t pid;
    signal(SIGCHLD, SIG_IGN);
    printf("before fork pid:%d\n", getpid());
    int abc = 10;
    pid = fork();
    
    if (pid == -1) {           //错误返回
        perror("tile");
        return -1;
    }
    
    if (pid > 0) {              //父进程空间
        abc++;
        printf("parent:pid:%d \n", getpid());
        printf("abc:%d \n", abc);
        sleep(20);
    }
    else if (pid == 0) {       //子进程空间
        abc++;
        printf("child:%d,parent: %d\n", getpid(), getppid());
        printf("abc:%d", abc);
    }
    printf("fork after...\n");
}
```
#### 36.用户态到内核态的转化原理
1、系统调用
```
这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完
成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。
```
2、异常
```
当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处
理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。
```
3、外围设备的中断
```
当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的
指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然
也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。
```

#### 37.微内核与宏内核
```
宏内核：除了最基本的进程、线程管理、内存管理外，将文件系统，驱动，网络协议等等都集成在内核里面，例如linux内核。
优点：效率高。

缺点：稳定性差，开发过程中的bug经常会导致整个系统挂掉。
```
```
微内核：内核中只有最基本的调度、内存管理。驱动、文件系统等都是用户态的守护进程去实现的。

优点：稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃

缺点：效率低。典型代表QNX，QNX的文件系统是跑在用户态的进程，称为resmgr的东西，是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。不过数据吞吐量就比较不乐观了。
```
#### 38.僵尸进程
1）正常进程
- 子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。
- unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 但是仍然为其保留一定的信息，直到父进程通过wait / waitpid来取时才释放。保存信息包括：
```
1进程号the process ID

2退出状态the termination status of the process

3运行时间the amount of CPU time taken by the process等
```
2）孤儿进程
- 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

3）僵尸进程
- 一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。
- 僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段
- 如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。
- 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。

4）危害
- 如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。

5）外部消灭：

- 通过kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源

6）内部解决：

- 1、子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。

- 2、fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。

#### 39.5种IO模型


1.阻塞IO:调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作

2.非阻塞IO:非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。

3.信号驱动IO:信号驱动IO:linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO时间就绪，进程收到SIGIO信号。然后处理IO事件。

4.IO复用/多路转接IO:linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检测。知道有数据可读或可写时，才真正调用IO操作函数

5.异步IO:linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。

#### 40.操作系统为什么要分内核态和用户态?

- 为了安全性。在cpu的一些指令中，有的指令如果用错，将会导致整个系统崩溃。
- 分了内核态和用户态后，当用户需要操作这些指令时候，内核为其提供了API，可以通过系统调用陷入内核，让内核去执行这些操作。

#### 41.操作系统怎么设计的page cache
- 加快从磁盘读取文件的速率。page cache中有一部分磁盘文件的缓存
- 因为从磁盘中读取文件比较慢，所以读取文件先去page cache中去查找，如果命中，则不需要去磁盘中读取，大大加快读取速度。
- 在 Linux 内核中，文件的每个数据块最多只能对应一个 Page Cache 项
- 它通过两个数据结构来管理这些 Cache
项，一个是radix tree，另一个是双向链表。Radix tree 是一种搜索树，Linux
内核利用这个数据结构来通过文件内偏移快速定位Cache项

#### 42.死循环+来连接时新建线程的方法效率有点低，怎么改进？
- 提前创建好一个线程池，用生产者消费者模型，创建一个任务队列，队列作为临界资源，有了新连接，就挂在到任务队列上，队列为空所有线程睡眠。
- 改进死循环：使用select epoll这样的技术

#### 43.两个进程访问临界区资源，会不会出现都获得自旋锁的情况？
- 单核cpu，并且开了抢占可以造成这种情况。

#### 44.请问怎么实现线程池
```
1.设置一个生产者消费者队列，作为临界资源
2.初始化n个线程，并让其运行起来，加锁去队列取任务运行
3.当任务队列为空的时候，所有线程阻塞
4.当生产者队列来了一个任务后，先对队列加锁，把任务挂在到队列上，然后使用条件变量去通知阻塞中的一个线程
```

#### 44.Linux下怎么得到一个文件的100到200行
```
sed -n '100,200p' inputfile
head -200 inputfile|tail -100
```
#### 45.awk的使用
1）作用：
- 样式扫描和处理语言。它允许创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。

## 四、计算机网络
### 常见问题

#### 1.请你说一下TCP怎么保证可靠性
（1）序列号、确认应答、超时重传
```
数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会说明了它下一
次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认
应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是2*RTT(报文段往返时间）+一个偏差值。
```
（2）窗口控制与高速重发控制/快速重传（重复确认应答）
```
TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据
，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。
```
（3）拥塞控制
```
如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，你在这狂发
，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP在为了防止这种情况而进行了拥塞控制
```
```
慢启动：定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到确认应答（经过一个rtt），将拥塞窗口大小*2。
```
```
拥塞避免：设置慢启动阈值，一般开始都设为65536。拥塞避免是指当拥塞窗口大小达到这个阈值，拥塞窗
口的值不再指数上升，而是加法增加（每次确认应答/每个rtt，拥塞窗口大小+1），以此来避免拥塞。
```

#### 2.三次握手
1. Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。

2. Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。

3. Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。

![](http://blog.chinaunix.net/attachment/201304/8/22312037_1365405910EROI.png)

#### 3.四次挥手
1.数据传输结束后，客户端的应用进程发出连接释放报文段，并停止发送数据，客户端进入FIN_WAIT_1状态，此时客户端依然可以接收服务器发送来的数据。

2.服务器接收到FIN后，发送一个ACK给客户端，确认序号为收到的序号+1，服务器进入CLOSE_WAIT状态。客户端收到后进入FIN_WAIT_2状态。

3.当服务器没有数据要发送时，服务器发送一个FIN报文，此时服务器进入LAST_ACK状态，等待客户端的确认

4.客户端收到服务器的FIN报文后，给服务器发送一个ACK报文，确认序列号为收到的序号+1。此时客户端进入TIME_WAIT状态，等待2MSL（MSL：报文段最大生存时间），然后关闭连接。

![](http://blog.chinaunix.net/attachment/201304/9/22312037_1365503104wDR0.png)

#### 4.IP地址作用，以及MAC地址作用
- MAC地址是一个硬件地址，用来定义网络设备的位置，主要由数据链路层负责。
- IP地址是IP协议提供的一种统一的地址格式，为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。

#### 5.OSI七层模型和TCP/IP四层模型，每层列举2个协议
OSI七层模型及其包含的协议如下:
```
物理层: 通过媒介传输比特,确定机械及电气规范,传输单位为bit，主要包括的协议为：IEE802.3 CLOCK RJ45


数据链路层: 将比特组装成帧和点到点的传递,传输单位为帧,主要包括的协议为MAC VLAN PPP


网络层：负责数据包从源到宿的传递和网际互连，传输单位为包,主要包括的协议为IP ARP ICMP


传输层：提供端到端的可靠报文传递和错误恢复，传输单位为报文,主要包括的协议为TCP UDP


会话层：建立、管理和终止会话，传输单位为SPDU，主要包括的协议为RPC NFS


表示层: 对数据进行翻译、加密和压缩,传输单位为PPDU，主要包括的协议为JPEG ASII


应用层: 允许访问OSI环境的手段,传输单位为APDU，主要包括的协议为FTP HTTP DNS
```

#### 6.搜索baidu，会用到计算机网络中的什么层？
浏览器中输入URL

浏览器要将URL解析为IP地址，解析域名就要用到DNS协议，首先主机会查询DNS的缓存，如果没有就给本地DNS发送查询请求。DNS查询分为两种方式，一种是递归查询，一种是迭代查询。如果是迭代查询，本地的DNS服务器，向根域名服务器发送查询请求，根域名服务器告知该域名的一级域名服务器，然后本地服务器给该一级域名服务器发送查询请求，然后依次类推直到查询到该域名的IP地址。DNS服务器是基于UDP的，因此会用到UDP协议。


得到IP地址后，浏览器就要与服务器建立一个http连接。因此要用到http协议，http协议报文格式上面已经提到。http生成一个get请求报文，将该报文传给TCP层处理，所以还会用到TCP协议。如果采用https还会使用https协议先对http数据进行加密。TCP层如果有需要先将HTTP数据包分片，分片依据路径MTU和MSS。TCP的数据包然后会发送给IP层，用到IP协议。IP层通过路由选路，一跳一跳发送到目的地址。当然在一个网段内的寻址是通过以太网协议实现(也可以是其他物理层协议，比如PPP，SLIP)，以太网协议需要直到目的IP地址的物理地址，有需要ARP协议。

#### 7.达到什么情况的时候开始减慢增长的速度？
采用慢开始和拥塞避免算法的时候
```
1. 一旦cwnd>慢开始门限，就采用拥塞避免算法，减慢增长速度

2. 一旦出现丢包的情况，就重新进行慢开始，减慢增长速度
```

#### 8.传递到IP层怎么知道报文该给哪个应用程序，它怎么区分UDP报文还是TCP报文?
- 根据端口区分；
- 看ip头中的协议标识字段，17是udp，6是tcp

#### 9.tcp握手为什么两次不可以？为什么不用四次？
- 两次不可以：tcp是全双工通信，两次握手只能确定单向数据链路是可以通信的，并不能保证反向的通信正常
- 不用四次：
本来握手应该和挥手一样都是需要确认两个方向都能联通的

#### 10.TCP和UDP的区别和各自适用的场景?
1）TCP和UDP区别
```
1） 连接

TCP是面向连接的传输层协议，即传输数据之前必须先建立好连接。

UDP无连接。

2） 服务对象

TCP是点对点的两点间服务，即一条TCP连接只能有两个端点；

UDP支持一对一，一对多，多对一，多对多的交互通信。

3） 可靠性

TCP是可靠交付：无差错，不丢失，不重复，按序到达。

UDP是尽最大努力交付，不保证可靠交付。

4）拥塞控制，流量控制

TCP有拥塞控制和流量控制保证数据传输的安全性。

UDP没有拥塞控制，网络拥塞不会影响源主机的发送效率。

5） 报文长度

TCP是动态报文长度，即TCP报文长度是根据接收方的窗口大小和当前网络拥塞情况决定的。

UDP面向报文，不合并，不拆分，保留上面传下来报文的边界。

6)   首部开销

TCP首部开销大，首部20个字节。

UDP首部开销小，8字节。（源端口，目的端口，数据长度，校验和）
```

2）TCP和UDP适用场景
```
选用TCP 协议（如文件传输、重要状态的更新等）；
使用 UDP 协议（如视频传输、实时通信等）。
```

#### 11.socket编程中服务器端和客户端主要用到哪些函数?
1）基于TCP的socket：
```
1、服务器端程序：

1创建一个socket，用函数socket()

2绑定IP地址、端口等信息到socket上，用函数bind()

3设置允许的最大连接数，用函数listen()

4接收客户端上来的连接，用函数accept()

5收发数据，用函数send()和recv()，或者read()和write()

6关闭网络连接

2、客户端程序：

1创建一个socket，用函数socket()

2设置要连接的对方的IP地址和端口等属性

3连接服务器，用函数connect()

4收发数据，用函数send()和recv()，或read()和write()

5关闭网络连接
```
2）基于UDP的socket：
```
1、服务器端流程

1建立套接字文件描述符，使用函数socket()，生成套接字文件描述符。

2设置服务器地址和侦听端口，初始化要绑定的网络地址结构。

3绑定侦听端口，使用bind()函数，将套接字文件描述符和一个地址类型变量进行绑定。

4接收客户端的数据，使用recvfrom()函数接收客户端的网络数据。

5向客户端发送数据，使用sendto()函数向服务器主机发送数据。

6关闭套接字，使用close()函数释放资源。UDP协议的客户端流程

2、客户端流程

1建立套接字文件描述符，socket()。

2设置服务器地址和端口，struct sockaddr。

3向服务器发送数据，sendto()。

4接收服务器的数据，recvfrom()。

5关闭套接字，close()。
```

#### 12.讲述一下Socket编程的send() recv() accept() socket()函数？
1.send函数用来向TCP连接的另一端发送数据。客户程序一般用send函数向服务器发送请求，而服务器则通常用send函数来向客户程序发送应答,send的作用是将要发送的数据拷贝到缓冲区，协议负责传输。

2.recv函数用来从TCP连接的另一端接收数据，当应用程序调用recv函数时，recv先等待s的发送缓冲中的数据被协议传送完毕，然后从缓冲区中读取接收到的内容给应用层。

3.accept函数用了接收一个连接，内核维护了半连接队列和一个已完成连接队列，当队列为空的时候，accept函数阻塞，不为空的时候accept函数从上边取下来一个已完成连接，返回一个文件描述符。

## 五、数据库
### 常见问题
#### 1.数据库事务隔离
同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。

#### 2.数据库的四个基本特征

1）原子性（Atomicity）

原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，[删删删]因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。

2）一致性（Consistency）

一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。

拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。

3）隔离性（Isolation）

隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。

4）持久性（Durability）

持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。

#### 3.索引是什么？
1、索引

数据库索引是为了增加查询速度而对表字段附加的一种标识，是对数据库表中一列或多列的值进行排序的一种结构。

2、优点：

通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。

可以大大加快数据的检索速度，这也是创建索引的最主要的原因。

3、缺点：

创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。

索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。

#### 4.数据库的三大范式
第一范式：当关系模式R的所有属性都不能再分解为更基本的数据单位时，称R是满足第一范式，即属性不可分

第二范式：如果关系模式R满足第一范式，并且R得所有非主属性都完全依赖于R的每一个候选关键属性，称R满足第二范式

第三范式：设R是一个满足第一范式条件的关系模式，X是R的任意属性集，如果X非传递依赖于R的任意一个候选关键字，称R满足第三范式，即非主属性不传递依赖于键码

#### 5.mysql的MVCC机制
- MVCC是一种多版本并发控制机制，是MySQL的InnoDB存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。
- MVCC是通过保存数据在某个时间点的快照来实现该机制，其在每行记录后面保存两个隐藏的列，分别保存这个行的创建版本号和删除版本号，然后Innodb的MVCC使用到的快照存储在Undo日志中，该日志通过回滚指针把一个数据行所有快照连接起来。

#### 6.SQL优化方法有哪些?
- 通过建立索引对查询进行优化
- 对查询进行优化，应尽量避免全表扫描

#### 7.mongodb和redis的区别
1.内存管理机制上

- Redis 数据全部存在内存，定期写入磁盘，当内存不够时，可以选择指定的 LRU 算法删除数据。
- MongoDB 数据存在内存，由 linux系统 mmap 实现，当内存不够时，只将热点数据放入内存，其他数据存在磁盘。

2.支持的数据结构上

- Redis 支持的数据结构丰富，包括hash、set、list等。
- MongoDB 数据结构比较单一，但是支持丰富的数据表达，索引，最类似关系型数据库，支持的查询语言非常丰富

#### 8.Redis是单线程的，但是为什么这么高效呢?
- 通过使用I/O多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型
- 又可以很好地与Redis服务器中其他同样以单线程运行的模块进行对接，这保持了Redis内部单线程设计的简单性。

#### 9.Redis和memcached的区别
```
1）数据类型 ：redis数据类型丰富，支持set liset等类型；memcache支持简单数据类型，需要客户端自己处理复杂对象
2）持久性：redis支持数据落地持久化存储；memcache不支持数据持久存储。)

3）分布式存储：redis支持master-slave复制模式；memcache可以使用一致性hash做分布式。

4）value大小不同：memcache是一个内存缓存，key的长度小于250字符，单个item存储要小于1M，不适合虚拟机使用

5）数据一致性不同：redis使用的是单线程模型，保证了数据按顺序提交；memcache需要使用cas保证数据一致性。CAS（Check and Set）是一个确保并发一致性的机制，属于“乐观锁”范畴；原理很简单：拿版本号，操作，对比版本号，如果一致就操作，不一致就放弃任何操作

6）cpu利用：redis单线程模型只能使用一个cpu，可以开启多个redis进程
```

#### 10.使用redis可能出现的问题
答： 在这里我们主要介绍Redis可能出现的三个问题，如下所示：

缓存雪崩：
举例：缓存同一时间大面积的失效，这个时候又来的一波请求都到数据库上，导致数据库连接异常。

解决办法：可以给缓存设置不同的缓存时间，更新数据使用互斥锁或者通过双缓存在避免缓存雪崩。


缓存穿透：
举例：故意的去请求缓存中不存在的数据，导致请求都打到了数据库上，导致数据库异常。

解决办法：可以使用互斥锁或者无论是否取到结果都将结果存入缓存，还可以使用有效的机制来拦截不合法的key值等。


数据库和缓存的双写一致性问题：
在高并发请求下很容易导致数据不一致的问题，如果你的业务需要保证数据的强一致性，那么建议不要使用缓存。在数据库中和缓存数据的删除或者写入过程中，如果有失败的情况，会导致数据的不一致。

#### 11.为什么 Redis 中要使用 I/O 多路复用这种技术呢？
首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的。

阻塞式的 I/O 模型并不能满足这里的需求，我们需要一种效率更高的 I/O 模型来支撑 Redis 的多个客户（redis-cli），这里涉及的就是 I/O 多路复用模型了。
Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）

文件事件处理器使用 I/O 多路复用模块同时监听多个 FD，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器。
虽然整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单。


## 六、设计模式
### 常见问题
#### 1.OOP的设计模式的五项原则
1、单一职责原则

单一职责有2个含义，一个是避免相同的职责分散到不同的类中，另一个是避免一个类承担太多职责。减少类的耦合，提高类的复用性。

2、接口隔离原则

表明客户端不应该被强迫实现一些他们不会使用的接口，应该把胖接口中额方法分组，然后用多个接口代替它，每个接口服务于一个子模块。简单说，就是使用多个专门的接口比使用单个接口好很多。

3、开放-封闭原则

open模块的行为必须是开放的、支持扩展的，而不是僵化的。

closed在对模块的功能进行扩展时，不应该影响或大规模影响已有的程序模块。一句话概括：一个模块在扩展性方面应该是开放的而在更改性方面应该是封闭的。

4、替换原则

子类型必须能够替换掉他们的父类型、并出现在父类能够出现的任何地方。

5、依赖倒置原则

上层模块不应该依赖于下层模块，他们共同依赖于一个抽象，即：父类不能依赖子类，他们都要依赖抽象类。

抽象不能依赖于具体，具体应该要依赖于抽象

#### 2.你用过哪些设计模式

单例模式：单例模式主要解决一个全局使用的类频繁的创建和销毁的问题。单例模式下可以确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。单例模式有三个要素：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。

工厂模式：工厂模式主要解决接口选择的问题。该模式下定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，使其创建过程延迟到子类进行。

观察者模式：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。

#### 3.你所知道的设计模式有哪些？

创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模
式、建造者模式、原型模式。

结构型模式，共七种：适配器模式、装饰器模式、代理模式、
外观模式、桥接模式、组合模式、享元模式。

行为型模式，共十一种：策略模式、模板方法模式、观察者模
式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。

#### 4.Android 中举几个例子说说用到了什么设计模式 ？

- AlertDialog、Notification 源码中使用了 Builder（建造者）
模式完成参数的初始化

- Okhttp 内部使用了责任链模式来完成每个 Interceptor 拦截
器的调用
- RxJava 的观察者模式；单例模式；GridView 的适配器模式；
Intent 的原型模式

- 日常开发的 BaseActivity 抽象工厂模式

## 七、git用法
#### 1. merge 和 rebase 的运行机制有什么不同

1. 可以看出merge结果能够体现出时间线，但是rebase会打乱时间线。 
2. 而rebase看起来简洁，但是merge看起来不太简洁。 
3. 最终结果是都把代码合起来了，所以具体怎么使用这两个命令看项目需要。
       

还有一点说明的是，在项目中经常使用git pull来拉取代码，git pull相当于是git fetch + git merge，如果此时运行git pull -r，也就是git pull –rebase，相当于git fetch + git rebase